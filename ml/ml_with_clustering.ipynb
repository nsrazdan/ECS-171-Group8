{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = \"ml.py\"\n",
    "#exec(compile(open(filename, \"rb\").read(), filename, 'exec'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "import dateutil.parser as parser\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/trevorcarpenter/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# read the dataset into pandas dataframe\n",
    "# df = pd.read_csv('./../downsampled_data', delim_whitespace=False).dropna()\n",
    "df = pd.read_csv('./../downsampled_data.csv').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function returns WSS score for k values from 1 to kmax\n",
    "def calculate_WSS(points, kmax, columns):\n",
    "    sse = []\n",
    "    for k in range(1, kmax+1):\n",
    "        kmeans = KMeans(n_clusters = k).fit(points)\n",
    "        centroids = kmeans.cluster_centers_\n",
    "        pred_clusters = kmeans.predict(points)\n",
    "        curr_sse = 0\n",
    "\n",
    "    # calculate square of Euclidean distance of each point from its cluster center and add to current WSS\n",
    "        for i in range(len(points)):\n",
    "            curr_center = centroids[pred_clusters[i]]\n",
    "            for j in range(len(columns)):\n",
    "                curr_sse += (float(points[i:i+1][columns[j]].values[0]) - curr_center[j]) ** 2\n",
    "                \n",
    "\n",
    "        sse.append(curr_sse)\n",
    "    return sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['categoryId'] = df['categoryId'].astype(np.float)\n",
    "\n",
    "categories = pd.DataFrame(np.zeros((len(df), len(df['categoryId'].unique()))), columns = df['categoryId'].unique())\n",
    "index = 0\n",
    "for id in df['categoryId']:\n",
    "    categories[id][index] = 1\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the first five rows\n",
    "retrieval_time = df['time_retrieved']\n",
    "publish_time = df['publishedAt']\n",
    "channel_publish_time = df['Channel_publishedAt']\n",
    "retrieval_time_11_19_14 = df['11_19_14_update_timestamp']\n",
    "columns_to_drop = ['Unnamed: 0', 'definition', 'categoryId', 'publishedAt', 'time_retrieved', 'Channel_title', '11_19_14_update_timestamp', 'Channel_publishedAt', 'video_id', 'channelId', 'thumbnail_link', 'Channel_country']\n",
    "df = df.drop(columns_to_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'channelTitle', 'duration', 'trended_later', 'tags',\n",
       "       'ratings_disabled', 'description', 'Channel_viewCount',\n",
       "       'Channel_subscriberCount', 'Channel_hiddenSubscriberCount',\n",
       "       'Channel_videoCount', 'Channel_description',\n",
       "       'view_count_update_11_19_14', 'likes_update_11_19_14',\n",
       "       'dislikes_update_11_19_14', 'comment_count_update_11_19_14',\n",
       "       'trending?', 'engagement_rate', 'INTL', 'UNK', 'USA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for column in categories.columns:\n",
    "    df.insert(df.shape[1], \"Category_\"+str(column), categories[column])\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/envs/newEnv/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Applications/anaconda2/envs/newEnv/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Applications/anaconda2/envs/newEnv/lib/python3.7/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Applications/anaconda2/envs/newEnv/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "## time updates\n",
    "import dateutil.parser as parser\n",
    "age = []\n",
    "age_update = []\n",
    "channel_age = []\n",
    "for i in df.index:\n",
    "    channel_publish_time[i] = channel_publish_time[i].replace(\"\\\"\", \"\")\n",
    "    age.append(parser.isoparse(retrieval_time[i]) - parser.isoparse(publish_time[i]))\n",
    "    age_update.append(parser.isoparse(retrieval_time_11_19_14[i]) - parser.isoparse(publish_time[i]))\n",
    "    channel_age.append(parser.isoparse(channel_publish_time[i]) - parser.isoparse(publish_time[i]))\n",
    "    if df['ratings_disabled'][i] == 'True':\n",
    "        df['ratings_disabled'][i] = True\n",
    "    elif df['ratings_disabled'][i] == 'False':\n",
    "        df['ratings_disabled'][i] = False\n",
    "        \n",
    "    if df['Channel_hiddenSubscriberCount'][i] == 'True':\n",
    "        df['Channel_hiddenSubscriberCount'][i] = True\n",
    "    elif df['Channel_hiddenSubscriberCount'][i] == 'False':\n",
    "        df['Channel_hiddenSubscriberCount'][i] = False\n",
    "        \n",
    "        \n",
    "    if df['trended_later'][i] == 'True':\n",
    "        df['trended_later'][i] = True\n",
    "    elif df['trended_later'][i] == 'False':\n",
    "        df['trended_later'][i] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sentiment values\n",
    "\n",
    "titles = df['title']\n",
    "channel_title = df['channelTitle']\n",
    "description = df['description']\n",
    "channel_description = df['Channel_description']\n",
    "\n",
    "title_sentiment_vals = []\n",
    "channel_title_sentiment_vals = []\n",
    "description_sentiment_vals = []\n",
    "channel_description_sentiment_vals = []\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "for sentence in titles:\n",
    "    ss = sid.polarity_scores(str(sentence))\n",
    "    title_sentiment_vals.append(ss['pos']-ss['neg'])\n",
    "    \n",
    "for sentence in channel_title:\n",
    "    ss = sid.polarity_scores(str(sentence))\n",
    "    channel_title_sentiment_vals.append(ss['pos']-ss['neg'])\n",
    "    \n",
    "for sentence in description:\n",
    "    ss = sid.polarity_scores(str(sentence))\n",
    "    description_sentiment_vals.append(ss['pos']-ss['neg'])\n",
    "    \n",
    "for sentence in channel_description:\n",
    "    ss = sid.polarity_scores(str(sentence))\n",
    "    channel_description_sentiment_vals.append(ss['pos']-ss['neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(['view_count_update_11_19_14',\n",
    "       #'likes_update_11_19_14', 'dislikes_update_11_19_14',\n",
    "       #'comment_count_update_11_19_14', 'engagement_rate'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "df['title'] = title_sentiment_vals\n",
    "df['channelTitle'] = channel_title_sentiment_vals\n",
    "df['description'] = description_sentiment_vals\n",
    "df['Channel_description'] = channel_description_sentiment_vals\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['trending?'] = le.fit_transform(df['trending?'])\n",
    "df['ratings_disabled'] = le.fit_transform(df['ratings_disabled'])\n",
    "df['Channel_hiddenSubscriberCount'] = le.fit_transform(df['Channel_hiddenSubscriberCount'])\n",
    "pd.set_option('display.max_columns', None)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = original_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(['view_count_update_11_19_14','likes_update_11_19_14', 'dislikes_update_11_19_14','comment_count_update_11_19_14', 'engagement_rate'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy values for now - get these interactively later...\n",
    "num_hidden_layers = 4\n",
    "num_hidden_layer_nodes = [20, 20, 30, 20]\n",
    "train_ratio = .7\n",
    "hidden_layer_activations = ['sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid']\n",
    "optimizer = 'adam'\n",
    "learning_rate = .005\n",
    "loss = 'mean_squared_error'\n",
    "metrics = [tf.keras.metrics.Accuracy(),tf.keras.metrics.Recall(),tf.keras.metrics.Precision()]\n",
    "metrics_names = [\"accuracy\",\"recall\",\"precision\"]\n",
    "epochs = 500\n",
    "batch_size = 200\n",
    "num_clusters = 3\n",
    "original_trend_values = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing set by 70:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.53465704e-02  4.72238267e-02 -1.36974387e-02  1.94404332e+01\n",
      "   1.08303249e-02  5.07833935e-02  2.44671939e-02  8.91076817e-02\n",
      "   0.00000000e+00 -1.34121515e-01  9.35306859e-02  5.68855072e-01\n",
      "   6.52799309e-01  3.55803245e-01  3.39545391e-01  1.76140201e-01\n",
      "   4.65703971e-01  1.69675090e-01  3.64620939e-01  2.27436823e-01\n",
      "   1.73285199e-01  4.69314079e-02  1.98555957e-01  4.69314079e-02\n",
      "   6.85920578e-02  3.97111913e-02  1.08303249e-01  2.16606498e-02\n",
      "   1.80505415e-02  1.44404332e-02  2.16606498e-02  3.61010830e-03\n",
      "   3.61010830e-03  3.61010830e-03  3.61010830e-03]\n",
      " [ 2.72054264e-02  1.45077519e-02 -4.00885061e-02  5.28294574e+00\n",
      "   3.87596899e-03  5.54844961e-02 -2.28418098e-01 -2.30385812e-01\n",
      "   0.00000000e+00 -6.55238816e-02  8.12054264e-02  1.18268661e-01\n",
      "   2.13593750e-01  1.33519468e-01  1.56010842e-01  1.46812465e-01\n",
      "   3.99224806e-01  2.98449612e-01  3.02325581e-01  1.89922481e-01\n",
      "   1.74418605e-01  4.65116279e-02  1.78294574e-01  3.87596899e-02\n",
      "   1.16279070e-01  4.65116279e-02  9.30232558e-02  3.87596899e-02\n",
      "   2.71317829e-02  1.55038760e-02  7.75193798e-03  1.16279070e-02\n",
      "   3.87596899e-03  7.75193798e-03  3.87596899e-03]\n",
      " [ 3.78711656e-02  1.02331288e-02 -1.71858993e-02  3.36196319e+01\n",
      "   6.07153217e-18  6.16748466e-02  7.14624560e-02  1.56979872e-01\n",
      "   0.00000000e+00 -8.48201922e-02  1.00957055e-01  4.93731892e-01\n",
      "   5.93884579e-01  4.14795706e-01  3.22011973e-01  5.84195441e-01\n",
      "   3.06748466e-01  2.39263804e-01  4.53987730e-01  1.96319018e-01\n",
      "   1.71779141e-01  2.45398773e-02  1.77914110e-01  6.13496933e-02\n",
      "   6.13496933e-02  4.90797546e-02  1.34969325e-01  5.52147239e-02\n",
      "   1.22699387e-02  1.84049080e-02  3.06748466e-02  6.13496933e-03\n",
      "   3.03576608e-18  2.60208521e-18  3.03576608e-18]]\n"
     ]
    }
   ],
   "source": [
    "# separate data into x and y - just random y for now..\n",
    "y_column = 'trending?'\n",
    "clusterer = KMeans(n_clusters = num_clusters)\n",
    "if not original_trend_values:\n",
    "    df = df.drop(['trending?','trended_later'], axis = 1)\n",
    "    clusters = clusterer.fit(df).labels_\n",
    "    print(clusterer.cluster_centers_)\n",
    "    if 'cluster' in df.columns:\n",
    "        df[\"cluster\"]= clusters\n",
    "    else:\n",
    "        df.insert(df.shape[1], \"cluster\", clusters)\n",
    "    y_column = 'cluster'\n",
    "    \n",
    "    \n",
    "ratio = 0.7\n",
    "train, test = train_test_split(df, train_size=ratio, random_state=42)\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "train_X = train.loc[:,train.columns != y_column]\n",
    "train_Y = train[y_column]\n",
    "test_X = test.loc[:,test.columns != y_column]\n",
    "test_Y = test[y_column]\n",
    "\n",
    "\n",
    "\n",
    "new_train_Y = train_Y\n",
    "new_test_Y = test_Y\n",
    "\n",
    "if not original_trend_values:\n",
    "    new_train_Y = []\n",
    "    new_test_Y = []\n",
    "    potential_y_values =np.zeros((num_clusters, num_clusters))\n",
    "    for c in range(num_clusters):\n",
    "        potential_y_values[c][c] = 1\n",
    "    for index in range(len(train_Y)):\n",
    "        new_train_Y.append(potential_y_values[train_Y[index]])\n",
    "    for index in range(len(test_Y)):\n",
    "        new_test_Y.append(potential_y_values[test_Y[index]])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'channelTitle', 'duration', 'tags', 'ratings_disabled',\n",
       "       'description', 'Channel_viewCount', 'Channel_subscriberCount',\n",
       "       'Channel_hiddenSubscriberCount', 'Channel_videoCount',\n",
       "       'Channel_description', 'view_count_update_11_19_14',\n",
       "       'likes_update_11_19_14', 'dislikes_update_11_19_14',\n",
       "       'comment_count_update_11_19_14', 'engagement_rate', 'INTL', 'UNK',\n",
       "       'USA', 'Category_24.0', 'Category_25.0', 'Category_26.0',\n",
       "       'Category_17.0', 'Category_22.0', 'Category_20.0', 'Category_1.0',\n",
       "       'Category_10.0', 'Category_23.0', 'Category_28.0', 'Category_2.0',\n",
       "       'Category_27.0', 'Category_19.0', 'Category_15.0', 'Category_29.0',\n",
       "       'Category_30.0', 'cluster'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df = df.drop('cluster', axis = 1)\n",
    "SSE = calculate_WSS(c_df, 10, c_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc55eb5bf50>]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(SSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/envs/newEnv/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Applications/anaconda2/envs/newEnv/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='ovr')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the logistic regression model - need clean data...\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR_model = LogisticRegression(multi_class='ovr')\n",
    "LR_model.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  0,  0],\n",
       "       [ 0, 72,  0],\n",
       "       [ 0,  1, 87]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "pred_Y = LR_model.predict(test_X);\n",
    "confusion_matrix(test_Y, pred_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fc57a69d5d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATwAAAEWCAYAAAD7MitWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlVklEQVR4nO3deZwU9Z3/8dd7BhAFBWS4DwElCiooIKi4xCMQiIl4JV7rlbgGE+ImWeP6y+GZTaJZs4kJLouGGGOUaIQEI4rGI2i8gBFFQBQRBAaFERQRFGbm8/ujaqCnp2e6Cnqmu6c+zzzqYVfV91v16c748VvH9/uVmeGcc0lQku8AnHOuuXjCc84lhic851xieMJzziWGJzznXGJ4wnPOJYYnPNfsJF0i6dmIZe+S9OOmjsklgye8FkjSKkmfy7D9REk1krZK+kjSckmXNnKcfpJMUnna9jJJOyStaoLwnWsynvCSp8LM2gMHAN8B7pB0aJY67SQdkbJ+PvB2UwXoXFPxhJdQFpgDbAKGZCn+B+DilPWLgLtTC0gaJOlpSR9IWiLptJR9nSXNlrRF0kvAwWl1D5P0uKRNYavzK3v15ZxrgCe8hJJUEialMmBFluL3AOdKKpU0CNgfeDHlWK2Bh4DHgK7At4A/prQcpwCfAD2Ar4ZLbd12wOPAvWHd84DbJR2+11/SuTSe8JKnp6QPgO3ALOC7ZvZyljprgeXA5whaenen7T8WaA/8zMx2mNmTwN+A8ySVAmcB15rZx2b2GvD7lLpfBFaZ2e/MrMrMyoEHgbP36ls6l4EnvOSpMLOOBPfwbgNOjljvbuASghbYPWn7egJrzKwmZdtqoBfQBWgFrEnbV+sgYFR4KfxBmIwvALpHjMu5yDzhJZSZfQr8J3CkpNMjVHkQOBVYaWar0/ZVAH0kpf499QXWARuBKqBP2r5aa4B/mFnHlKW9mV0R7xs5l50nvJartaS2KUur9AJmtgO4Fbg228HM7GOC1uBlGXa/CHwMXC2ptaQTgS8BM8ysGpgJXC9pP0mDqfsA5G/AZyRdGNZtLemY8F6hcznlCa/lmkNwn652ub6BctOBvpK+lO2AZrbAzN7KsH0HcBowAagEbgcuMrPXwyKTCe7xvQvcBfwupe5HwDjgXIKW4rvAzcA+2eJxLi75AKDOuaTwFp5zLjE84TnnEsMTnnMuMTzhOecSo96rCvm0z/4dbb/OPfMdRsEa0Hm/fIfgitzq1auorKzU3hyj9ICDzKq2Rypr2zfONbPxe3O+XCqohLdf556c9KM/5DuMgnXvxcPzHYIrcqNHjdjrY1jVdvY5NNr4Dp8smlK21yfMoYJKeM65YiBQcd4N84TnnItHQElpvqPYI57wnHPxaa9uA+ZNcbZLnXN5FF7SRlmyHUkaHw76ukLSNY2UO0ZStaSz49ZN5QnPORefFG1p9BAqJRgcdgIwmGD8xMENlLsZmBu3bjpPeM65eESuWngjgRVmtjIcgGIGMDFDuW8RDE+2YQ/q1uEJzzkXU8TWXdDCK5O0IGW5POVAvag7MOzacNvuM0m9gDOAqWlBZK2biT+0cM7FF/0pbaWZNfTyX6Zr3vThm34J/KeZVavuJXKUuvV4wnPOxZSz9/DWUnck7N4EYyKmGgHMCJNdGfAFSVUR69bjCc85F4/I1Wsp84GBkvoTTAdwLsGcx7uYWf9dp5XuAv5mZn8JR/ButG4mnvCcc/HloIVnZlWSJhM8fS0FppvZEkmTwv3p9+2y1s12Tk94zrmYcte1LJwMfk7atoyJzswuyVY3G094zrl4BJR61zLnXFIUadcyT3jOuZh8tBTnXJJ4C885lxjewnPOJUKEgQEKlSc851x8PgCocy4Z/KGFcy5J/JLWOZcItePhFSFPeM65mPyS1jmXJP7QwjmXGH4PzzmXCPJLWudckngLzzmXFPKE55xLgmCE9+JMeMV5Ie6cyx8JlURbsh9K4yUtl7RC0jUZ9k+U9KqkReE0jyek7FslaXHtviihJ7KFN6TnAVw0sg8lgqferOSh196rs390/wP50hHdAPikqobpL7zDO5u379ovwX+dOohN23bw30++1ayxF4q/P7eU/3frn6muqeHCicfznUvG5TukgtLSf59ctPAklQJTgLEEs5DNlzTbzJamFHsCmG1mJmkIcD9wWMr+k8ysMuo5m7SFly1754MElx7bl1v+/ibf++tSju9/IL06tK1TZsPWT7lp7htc89AyZr26nsuOO6jO/gmDurLuw0+aM+yCUl1dw/duuZ8HfvUNXrj/hzz42EJeX7k+32EVjCT8PpIiLVmMBFaY2Uoz2wHMACamFjCzrWZWO99sOyLMPduYJkt4Kdl7AjAYOE/S4KY6X1SHlLXjvS2fsGHrDqprjOff3szwPh3rlHlz48d8vKMagBUbP+bAdq137Ttwv9Yc1bsDT70Z+T8qLc7CJasY0KeMfr3LaNO6FWeOHcacf7ya77AKRhJ+nxgJryy8FK1dLk85TC9gTcr62nBb+rnOkPQ68DDw1ZRdBjwmaWHacRvUlC28rNk7Hzrt15r3P965a33Tth11Elq6EweW8craLbvWLzymD/ctWMfu/+gkz/qNH9KrW6dd6z27dWL9xg/zGFFhafG/j2IsUGlmI1KWaWlHSlfvXywzm2VmhwGnAzel7BptZsMIGlXflDQmW+hNmfAiZe/mlvEXbiB3De7enhMP6cx95WsBOLp3B7Z8spO3N21rugCLQKZkX6QP7ZpES/99RLTWXYRL2rVAn5T13kBFQ4XNbB5wsKSycL0i/OcGYBZBI6tRTfnQIlL2DpuilwPse2D3JgwnsGnbTjrXuURtw+ZtO+uV69NpX/7t+H7c/Pc32fppcHn7ma7tGNanI0f17kDr0hL2bV3KN07ox+3PrmryuAtJz64dWffe5l3rFe9tpntZhzxGVFiS8PuUlOSkrTQfGCipP7AOOBc4P7WApEOAt8KHFsOANsD7ktoBJWb2Ufh5HHBjthM2ZcKLlL3DJu40gE79Bjf5deJblR/T/YC2dGnfhk3bdnJc/0785pm365Tp3K413zlxALc/8zbvbvl01/Y/lVfwp/LgKwzq1p5TD++WuGQHMGzwQbz1zkZWr6ukR9eOzHy8nDtuuiTfYRWMJPw+uXhKa2ZVkiYDc4FSYLqZLZE0Kdw/FTgLuEjSTmA7cE6Y/LoBs8I4WgH3mtmj2c7ZlAkva/bOhxqDu158h2s+N5CSEvH0m5Ws++ATTvlMGQBPvFHJmUN6sv8+rbj02L5BnRrjhw+/ns+wC0qrVqXccvVXOOvKKVRXGxecdiyDDu6R77AKRov/fXbfn9trZjYHmJO2bWrK55uBmzPUWwkMjXu+Jkt4DWXvpjpfHIvWbWHRurqhPPHG7qeudzy/mjueX93oMZa9t5Vl721tkviKwbjRhzNu9OH5DqNgtfTfp1h7WjTpi8eZsrdzrrjVPrQoRonsaeGc2ztRuo0VIk94zrl45Je0zrkE8YTnnEsMT3jOuUTwhxbOuWQpznznCc85F5Ny1rWs2XnCc87F5pe0zrnkKM585wnPOReft/Ccc4kQcay7guQJzzkXmyc851xieF9a51xieAvPOZcMRTx4QHG+PeicyxsRTEoUZcl6rCxzV0uaKOlVSYvCaR5PiFo3E2/hOediys1T2pS5q8cSzIEzX9JsM1uaUuwJYHY4j8UQ4H7gsIh16/EWnnMutpISRVqyyDp3tZlttd3zXrZj98yHezTvtSc851w8ES9nw0ZgWXgpWrtcnnKkSHNXSzpD0uvAw8BX49RN55e0zrlYBFFab7UqzWxEI4dKV2+qVjObRTAl4xjgJuBzUeum84TnnIstRw9pI81dXcvM5kk6WFJZ3Lq1/JLWORdbbfeybEsWu+aultSGYO7q2WnnOUThgSQNA9oA70epm4m38Jxz8UR85SSbhuauljQp3D8VOAu4SNJOYDtwTvgQY4/mvfaE55yLRShnA4Bmmrs6THS1n28Gbo5aNxtPeM652Iq0o4UnPOdcfMXatcwTnnMunhzdw8sHT3jOuViCvrTFmfE84TnnYivSfOcJzzkXX4yeFgXFE55zLp4iHg+voBLegM77ce/Fw/MdRsHq+dV78x1CwauYfn6+Q2jxasfDK0YFlfCcc8XAZy1zziVIkeY7T3jOuZjkDy2ccwnh7+E55xLFE55zLjGKNN95wnPOxectPOdcMvjgAc65pAgGAC3OjOdzWjjnYiuRIi3ZSBovabmkFZKuybD/Akmvhstzkoam7FslabGkRZIWRInbW3jOudhycUkrqRSYAowlmIVsvqTZZrY0pdjbwGfNbLOkCcA0YFTK/pPMrDLqOT3hOediUe4GDxgJrDCzlcFxNQOYCOxKeGb2XEr5FwimY9xjfknrnIutRNGWLHoBa1LW14bbGvI14JGUdQMek7RQ0uVR4m6whSfp1zQyk7eZXRnlBM65lifGQ4uytPtr08xsWvg500Ey5hxJJxEkvBNSNo82swpJXYHHJb1uZvMaC6axS9pINwGdc8kigie1EVWa2YgG9q0F+qSs9wYq6p1PGgLcCUwws/drt5tZRfjPDZJmEVwi71nCM7Pfp520nZl93NjBnHPJkKO3UuYDAyX1B9YB5wJ1BjSU1BeYCVxoZm+kbG8HlJjZR+HnccCNWePOVkDScZKWAsvC9aGSbo/+nZxzLYqC8fCiLI0xsypgMjCXIL/cb2ZLJE2SNCksdi3QGbg97fWTbsCzkl4BXgIeNrNHs4Ue5SntL4HPA7PDIF+RNCZCPedcC5WrnhZmNgeYk7Ztasrny4DLMtRbCQxN355NpNdSzGxNWraujnsi51zLIIj0UnEhipLw1kg6HjBJbYArCS9vnXPJ1JK7lk0Cvknwfsw64Khw3TmXQFL0pdBkbeGF3TYuaIZYnHNFolgvaaM8pR0g6SFJGyVtkPRXSQOaIzjnXGFSxKXQRLmkvRe4H+gB9AQeAO5ryqCcc4UtF6+l5EOUhCcz+4OZVYXLPTTS5cw517IFT2lz0pe22TXWl/bA8ONT4ThVMwgS3TnAw80Qm3OuEKl4BwBt7KHFQoIEV/vNvp6yz4Cbmioo51xhK8TL1Sga60vbvzkDcc4Vh9pL2mIUqaeFpCOAwUDb2m1mdndTBeWcK2wtroVXS9J1wIkECW8OMAF4FvCE51xCFWe6i/aU9mzgFOBdM7uUoMPuPk0alXOuYElQWqJIS6GJckm73cxqJFVJOgDYALToF4///txS/t+tf6a6poYLJx7Pdy4Zl++Qmt2JR/TgpvOHUyJx3zNv8Zs5S+vs//xRvfjeGUMwg6qaGq67r5yX3ty4a3+JxKPXfp71H2zn4l/9o7nDz7uW/jfUYi9pgQWSOgJ3EDy53Uow/lSjJE0HvghsMLMj9ibI5lRdXcP3brmfWb+ZTM9uHTn54p8zYcyRHDagR75DazYlEj/51xGce+uTrN+0nTnXfp65i9byZsWWXWWeWfYecxcF0wsM6t2R/7tiNGN+sPttpcvGHsqb67fQft/WzR5/viXhb6hI8132S1oz+4aZfRCOUTUWuDi8tM3mLmD8XsbX7BYuWcWAPmX0611Gm9atOHPsMOb849V8h9Wsjh7QmVUbtvLOxo/ZWV3DX19czeePqjtZ1LZPq3Z93m+fVljKq+g9Ou3LKUN6cu+8t5or5ILS0v+GRLQ5aQuxv21jLx4Pa2yfmZU3dmAzmyep317ElhfrN35Ir26ddq337NaJha+tyl9AedC9475UbNo9mv/6zdsYNqCsXrnxw3rz/bOG0nn/tlyUctl6w3nD+fEDL9O+bfJad5CAv6ECHQklisYuaW9tZJ8BJ+cigHB6tcsB+vTtm4tD7hWz+r3mivX/3D2V6ftm+l0eLV/Lo+VrGfWZLlx9xhDO+e8n+dzQnlRu+YTFqzdz3KFdmyHawpOEv6EWdw/PzE5qjgDCKdumAQwfPiLvfXR7du3Iuvc271qveG8z3cs65DGi5rd+83Z6Hthu13qPTvvx7gfbGyz/4hsbOahLew5svw/HHNKFcUf15pQhPdmndSn7t23Nr//tOL51x/PNEXpBaOl/QwJKc5TwJI0HfgWUAnea2c/S9l8A/Ge4uhW4wsxeiVI3E5+IO82wwQfx1jsbWb2ukh07q5j5eDkTxgzJd1jNatHb79O/2/70KWtH69ISJo46iMcWratTpl/X9rs+H9m3E61blbBp66f89MFXGHHVXxh19WyumPpPnn39vUQlO0jG31AuBg+QVApMIXi3dzBwnqTBacXeBj5rZkMIurNOi1G3nkg9LZKkVatSbrn6K5x15RSqq40LTjuWQQe3nKdrUVTXGD+4ZwH3fvckSkvEjGdX8kbFh1x44iEA/OHpFZw6vA9nH9+fqmpj+45qrpj6zzxHXTiS8DeUo1fsRgIrwgl5kDQDmAjsegfKzJ5LKf8Cwdy1kepm0mQJT9J9BD00yiStBa4zs9821flyadzowxk3+vB8h5FXTy6u4MnFdedE/sPTK3Z9nvLIMqY80vjUJs8v38Dzyzc0SXyFriX/DQXDt0fOeGUpUysCTAtvY0EwbcSalH1rgVGNHOtrwCN7WBeI1rVMBEO8DzCzG8OJcbubWaPv4pnZedmO7ZwrTjFaeJVmNqKBfZmOkvE+vqSTCBLeCXHrpopyD+924DigNoF9RHDt7JxLqBxN4rMW6JOy3huoSC8kaQhwJzDRzN6PUzddlEvaUWY2TNLLAGa2OZyu0TmXQAJa5eYp7XxgoKT+BDMingucX+dcwRXlTOBCM3sjTt1MoiS8neETEQsD6ALURKjnnGuhcpHvzKxK0mRgLsGrJdPNbImkSeH+qcC1QGfg9vC+YZWZjWiobrZzRkl4twGzgK6S/otg9JQfxv96zrmWQDnsNmZmcwiGnUvdNjXl82XAZVHrZhNlXto/SlpIMESUgNPNrPHHc865Fq1IO1pEekrbF9gGPJS6zczeacrAnHOFqwCHuoskyiXtw+yezKct0B9YDrTMl4ycc40SFOTgnlFEuaQ9MnU9HEXl6w0Ud861dAU652wUsXtamFm5pGOaIhjnXHFQkc5qEeUe3ndTVkuAYcDGBoo751q4lj5N4/4pn6sI7uk92DThOOeKQYtMeOELx+3N7HvNFI9zrgi0uAFAJbUK32ZucKh351zyBNM05juKPdNYC+8lgvt1iyTNBh4Adk10YGYzmzg251yBKsQJeqKIcg/vQOB9gjksat/HM4IOvc65hGmpDy26hk9oX2N3oquV97knnHP5U6QNvEYTXinQnj0caM8511KJkhb4Ht56M7ux2SJxzhUF0TJbeEX6lZxzTUrQqkhv4jWW8E5ptiicc0WjRbbwzGxTcwbinCsexfpaSpG+Puicy6ccTeKDpPGSlktaIemaDPsPk/S8pE8lXZW2b5WkxZIWpU0F2SCfiNs5F4vITUsp7Lo6BRhLMAvZfEmzzSx1Mu1NwJXA6Q0c5iQzq4x6Tm/hOefiUXBJG2XJYiSwwsxWmtkOYAYwMbWAmW0ws/nAzlyE7gnPORdL0NMicsIrk7QgZbk85VC9gDUp62vDbVEZ8JikhWnHbZBf0jrnYovxyKLSzEbEOEycTg2jzaxCUlfgcUmvm9m8xip4C885F1uOHlqsBfqkrPcGKqLGYGYV4T83EEwlOzJbHU94zrmYhBRtyWI+MFBSf0ltgHOB2ZEikNpJ2r/2MzCOoN9/o/yS1jkXS66e0objbU4G5hL03Z9uZkskTQr3T5XUHVgAHADUSPo2MBgoA2aFSbUVcK+ZPZrtnJ7wnHOx5erFYzObA8xJ2zY15fO7BJe66bYAQ+OezxNeEVl753n5DqHgdTpmcr5DKGifLn9n7w+iFjjEu3POZZKrS9p88ITnnIvNW3jOucQoznTnCc85F5OAUm/hOeeSokjznSc851xcQkV6UesJzzkXm7fwnHOJELyWUpwZzxOecy6eiKMZFyJPeM652Ip1TgtPeM65WIIBQPMdxZ7xhOeci82f0jrnEqNIr2g94Tnn4vMWnnMuEfwennMuOaJNwViQinVYK+dcHinikvU40nhJyyWtkHRNhv2HSXpe0qeSropTNxNv4TnnYqmdl3avjyOVAlOAsQQzmM2XNNvMlqYU2wRcCZy+B3Xr8Raecy62HLXwRgIrzGylme0AZgATUwuY2QYzmw/sjFs3E094zrn4ome8MkkLUpbLU47SC1iTsr423BbFHtX1S1rnXGwxLmkrzWxEA/syHcQiHneP6nrCc87FlqNntGuBPinrvYGKpqzrl7TOufhycxNvPjBQUn9JbYBzgdkRI9ijut7Cc87FEuSyvW/jmVmVpMnAXKAUmG5mSyRNCvdPldQdWAAcANRI+jYw2My2ZKqb7Zye8Jxz8eRwPDwzmwPMSds2NeXzuwSXq5HqZuMJzzkXW3H2s/CE55yLTT4Rt3MuOYo033nCc87FE7WfbCHyhOeci69IM54nPOdcbMU6AKi/eJzB359byjFn3ciwM67nf+56LN/hNJknnl/KyC/fxIizbuCXv6//Pc2Ma279MyPOuoF/ueCnvPL6msh1f3PPE3Qe9S3e/2ArADurqvnGDX/ghPN/wrHn/Ljof9dTjhvES3/+EQtnXse3Lx7bYLmjB/el8oXbOO3ko3Zt+/WPLuCNuT/luRnfb4ZIm4YUbSk0TZbwJPWR9JSkZZKWSPr3pjpXLlVX1/C9W+7ngV99gxfu/yEPPraQ11euz3dYOVddXcPVP3+A+395Bc/N+AEzM3zPvz+3lJVrNjD/z9fyi2vO5apb/hSp7rr3NvP0S6/Tu3unXdv++sTL7NhRxbP3fp8nf381v//LP3mn4v3m+bI5VlIifn71V/jyv9/OsV/5MWeNG86h/btnLHf95Ik8+cKyOtvv+9sLnH3llOYKN/ciJrtEJTygCvgPMxsEHAt8U9LgJjxfTixcsooBfcro17uMNq1bcebYYcz5x6v5Divnypeupn/vMvr1Cr7nGWOH88i8xXXKPDJvMedMGIkkjjmyPx9+tJ13Kz/MWvcH/zOT6ydPrPPqgoBtn+ygqqqaTz7dSZtWpezfrm1zfd2cGn54P1auqWT1uvfZWVXNzMfL+cJnh9Qrd/k5n+Whp15h4+aP6mx/7uW32LxlW3OF2yQU8X+FpskSnpmtN7Py8PNHwDKiD/2SN+s3fkivbrtbJj27dWL9xg/zGFHTWL/hg7rfs2tH1m/8oG6ZjZnKfNho3UfmLaZHlw4c8Zm6L8efdsrR7Ne2DYNP/SFDT7uWb15wCp06tMv9F2sGPbp0YN17m3etV7y3mR5dOtQr88UThzL9wWeaO7wmJ4q3hdcsDy0k9QOOBl5sjvPtDbP6I8wU4v9xeyvTODrpL5Nm/C0aqbvtkx384q65PHjbN+vtL1+ymtLSEpY8/GM+2LKNU7/+Sz478lD69Srbsy+QR5leuk3/qX7y3bO4/td/paYm6mhHxaVY/5Vo8oQnqT3wIPBtM9uSYf/lwOUAffr2bepwsurZtWO9/3p3L+vQSI3iVO97bvig3vfs2bVT/TJdOrCzqjpj3VVrK3mn4n3G/OvPdm0/6aJbePx3V/HnuQs4+dhBtG5VSpcD92fUkAEsWvZOUSa8ivQWbrdOvFtZ9yrg6EF9+e1/XQrAgR3bM/b4w6mqrmk5t0eKNOM16VNaSa0Jkt0fzWxmpjJmNs3MRpjZiC5lXZoynEiGDT6It97ZyOp1lezYWcXMx8uZMKb+/Zlid/Sgvqxcs5HVFcH3nPX4QiaMObJOmfH/cgR/euQlzIz5i9/mgPZt6V7WocG6gw/pyfJHf8qiv9zAor/cQM+uHXnq7qvp1vkAenfvxDML3sDM+Hj7pyx4bRUDD+qWp2+/d8qXrubgvl3o27MzrVuVcubYYTwyr24iO+r06xk68TqGTryO2U++zFU3/6nlJDuCAUCjLIWmyVp4Ctr9vwWWmdkvmuo8udaqVSm3XP0VzrpyCtXVxgWnHcugg3vkO6yca9WqlJuv+jJfvvJ2qmuM8790LIcN6MHvZj4LwKVnnsDY0Yfz+HNLGXHWjezbtjW//tG/Nlq3MV87ewzfuukeRp/3E8zg/C+O4vCBBX9LN6Pq6hquvuV+Hrztm5SWij/OfoHXV77LpWeeALDrN2zInT++hNHDB9K5Y3te+9tN/GzaHO6Z/XxzhJ4zhZfKolGm+zQ5ObB0AvAMsBioCTd/PxzSJaPhw0fYP19c0CTxtAQt9X5QLnUe9a18h1DQPl1+PzXbNuxVvjpi6DCb+VjjSb3Wod3bLWxkiPdm12QtPDN7luL9D4FzrgG5GgA0H7xrmXMungJ95SQK71rmnIstR/PSImm8pOWSVki6JsN+Sbot3P+qpGEp+1ZJWixpkaRI98K8heeciyk3A4BKKgWmAGMJZiGbL2m2mS1NKTYBGBguo4D/Df9Z6yQzq4x6Tm/hOediy1FPi5HACjNbaWY7gBnAxLQyE4G7LfAC0FHSHr824QnPORdL1MvZCG3AXsCalPW11O9+2lgZAx6TtDDswJCVX9I65+KLfkVblnZ/bZqZTWvkKOnvXjVWZrSZVUjqCjwu6XUzm9dYMJ7wnHOxxXgtpbKR9/DWAn1S1nsDFVHLmFntPzdImkVwidxowvNLWudcbDm6hzcfGCipv6Q2wLnA7LQys4GLwqe1xwIfmtl6Se0k7R/EonbAOOC1bCf0Fp5zLh5BSQ7ewzOzKkmTgblAKTDdzJZImhTun0ow0fYXgBXANuDSsHo3YFb4tLgVcK+ZPZrtnJ7wnHN7IDdvHoddTeekbZua8tmAeuONmdlKYGjc83nCc87FUjsAaDHyhOeci61I850nPOdcfN7Cc84lRi66luWDJzznXGzFme484TnnYirUGcmi8ITnnIvNBwB1ziVHceY7T3jOufiKNN95wnPOxVWYUzBG4QnPORdLMfe08NFSnHOJ4S0851xsxdrC84TnnIvNX0txziWDv3jsnEuKYn5o4QnPORebX9I65xKjWFt4/lqKcy62HM1Li6TxkpZLWiHpmgz7Jem2cP+rkoZFrZuJJzznXHw5yHiSSoEpwARgMHCepMFpxSYAA8PlcuB/Y9StxxOecy4WASVSpCWLkcAKM1tpZjuAGcDEtDITgbst8ALQUVKPiHXrKah7eOXlCyv3ba3V+Y4jRRlQme8gCpj/PtkV2m900N4eoLx84dx9W6ssYvG2khakrE8zs2nh517AmpR9a4FRafUzlekVsW49BZXwzKxLvmNIJWlBI7OmJ57/Ptm1xN/IzMbn6FCZmoAWsUyUuvUUVMJzziXKWqBPynpvoCJimTYR6tbj9/Ccc/kyHxgoqb+kNsC5wOy0MrOBi8KntccCH5rZ+oh16/EWXuOmZS+SaP77ZOe/UQPMrErSZGAuUApMN7MlkiaF+6cCc4AvACuAbcCljdXNdk6ZZb3sdc65FsEvaZ1zieEJzzmXGJ7wMtiTLitJImm6pA2SXst3LIVIUh9JT0laJmmJpH/Pd0wu4Pfw0oRdVt4AxhI8Ep8PnGdmS/MaWAGRNAbYSvAG/BH5jqfQhD0BephZuaT9gYXA6f43lH/ewqtvj7qsJImZzQM25TuOQmVm682sPPz8EbCMoGeAyzNPePU11JXFudgk9QOOBl7McygOT3iZ7FGXFefSSWoPPAh828y25Dse5wkvkyjdXZxrlKTWBMnuj2Y2M9/xuIAnvPr2qMuKc7UkCfgtsMzMfpHveNxunvDSmFkVUNtlZRlwf5QuK0ki6T7geeBQSWslfS3fMRWY0cCFwMmSFoXLF/IdlPPXUpxzCeItPOdcYnjCc84lhic851xieMJzziWGJzznXGJ4wisikqrDVxxek/SApP324lh3STo7/HxnY3N6SjpR0vF7cI5VUv3ZrRranlZma8xzXS/pqrgxumTxhFdctpvZUeEIJTuASak7w5FeYjOzy7KM5HEiEDvhOVdoPOEVr2eAQ8LW11OS7gUWSyqV9HNJ8yW9KunrELz9L+k3kpZKehjoWnsgSU9LGhF+Hi+pXNIrkp4IO79PAr4Tti7/RVIXSQ+G55gvaXRYt7OkxyS9LOn/yDr3PEj6i6SF4bhxl6ftuzWM5QlJXcJtB0t6NKzzjKTDcvJrukTwSXyKkKRWwATg0XDTSOAIM3s7TBofmtkxkvYB/inpMYIROw4FjgS6AUuB6WnH7QLcAYwJj3WgmW2SNBXYamb/HZa7F/gfM3tWUl+CXimDgOuAZ83sRkmnAnUSWAO+Gp5jX2C+pAfN7H2gHVBuZv8h6drw2JMJJsWZZGZvShoF3A6cvAc/o0sgT3jFZV9Ji8LPzxD01zweeMnM3g63jwOG1N6fAzoAA4ExwH1mVg1USHoyw/GPBebVHsvMGhrz7nPA4KDLKAAHhANdjgHODOs+LGlzhO90paQzws99wljfB2qAP4Xb7wFmhqOPHA88kHLufSKcwznAE16x2W5mR6VuCP/F/zh1E/AtM5ubVu4LZB/mShHKQHAr5Dgz254hlsh9FSWdSJA8jzOzbZKeBto2UNzC836Q/hs4F5Xfw2t55gJXhMMTIekzktoB84Bzw3t8PYCTMtR9HvispP5h3QPD7R8B+6eUe4zg8pKw3FHhx3nABeG2CUCnLLF2ADaHye4wghZmrRKgtpV6PsGl8hbgbUlfDs8hSUOznMO5XTzhtTx3EtyfK1cwyc7/EbTkZwFvAouB/wX+kV7RzDYS3HebKekVdl9SPgScUfvQArgSGBE+FFnK7qfFNwBjJJUTXFq/kyXWR4FWkl4FbgJeSNn3MXC4pIUE9+huDLdfAHwtjG8JPvy+i8FHS3HOJYa38JxzieEJzzmXGJ7wnHOJ4QnPOZcYnvCcc4nhCc85lxie8JxzifH/AbXqLgEh6iVHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "disp = plot_confusion_matrix(LR_model, test_X, test_Y, cmap=plt.cm.Blues, normalize = 'all')\n",
    "disp.ax_.set_title(\"LR Model\")\n",
    "disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9952380952380953\n"
     ]
    }
   ],
   "source": [
    "# evaluate the accuracy of the LR model\n",
    "accuracy = LR_model.score(test_X, test_Y)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                720       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 30)                630       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 63        \n",
      "=================================================================\n",
      "Total params: 2,873\n",
      "Trainable params: 2,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the ANN model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "ANN_model = keras.Sequential()\n",
    "\n",
    "# add hidden layers\n",
    "for i in range(num_hidden_layers):\n",
    "    if i == 0:\n",
    "        ANN_model.add(Dense(num_hidden_layer_nodes[i], input_dim = train_X.shape[1], activation=hidden_layer_activations[i]))\n",
    "    ANN_model.add(Dense(num_hidden_layer_nodes[i], activation=hidden_layer_activations[i]))\n",
    "\n",
    "# add output layers\n",
    "ANN_model.add(Dense(1 if original_trend_values else num_clusters, activation=hidden_layer_activations[num_hidden_layers]))\n",
    "\n",
    "ANN_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "ANN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 488 samples, validate on 210 samples\n",
      "Epoch 1/500\n",
      "488/488 [==============================] - 1s 2ms/sample - loss: 0.2847 - accuracy: 0.0000e+00 - recall: 0.6230 - precision: 0.3115 - val_loss: 0.2853 - val_accuracy: 0.0000e+00 - val_recall: 0.5810 - val_precision: 0.2905\n",
      "Epoch 2/500\n",
      "488/488 [==============================] - 0s 63us/sample - loss: 0.2779 - accuracy: 0.0000e+00 - recall: 0.6230 - precision: 0.3115 - val_loss: 0.2785 - val_accuracy: 0.0000e+00 - val_recall: 0.5810 - val_precision: 0.2905\n",
      "Epoch 3/500\n",
      "488/488 [==============================] - 0s 110us/sample - loss: 0.2716 - accuracy: 0.0000e+00 - recall: 0.6230 - precision: 0.3115 - val_loss: 0.2721 - val_accuracy: 0.0000e+00 - val_recall: 0.5810 - val_precision: 0.2905\n",
      "Epoch 4/500\n",
      "488/488 [==============================] - 0s 63us/sample - loss: 0.2655 - accuracy: 0.0000e+00 - recall: 0.6230 - precision: 0.3115 - val_loss: 0.2662 - val_accuracy: 0.0000e+00 - val_recall: 0.5810 - val_precision: 0.2905\n",
      "Epoch 5/500\n",
      "488/488 [==============================] - 0s 78us/sample - loss: 0.2601 - accuracy: 0.0000e+00 - recall: 0.5615 - precision: 0.3086 - val_loss: 0.2606 - val_accuracy: 0.0000e+00 - val_recall: 0.2381 - val_precision: 0.2381\n",
      "Epoch 6/500\n",
      "488/488 [==============================] - 0s 77us/sample - loss: 0.2550 - accuracy: 0.0000e+00 - recall: 0.2807 - precision: 0.2807 - val_loss: 0.2554 - val_accuracy: 0.0000e+00 - val_recall: 0.2381 - val_precision: 0.2381\n",
      "Epoch 7/500\n",
      "488/488 [==============================] - 0s 77us/sample - loss: 0.2503 - accuracy: 0.0000e+00 - recall: 0.2807 - precision: 0.2807 - val_loss: 0.2506 - val_accuracy: 0.0000e+00 - val_recall: 0.2381 - val_precision: 0.2381\n",
      "Epoch 8/500\n",
      "488/488 [==============================] - 0s 80us/sample - loss: 0.2460 - accuracy: 0.0000e+00 - recall: 0.2807 - precision: 0.2807 - val_loss: 0.2462 - val_accuracy: 0.0000e+00 - val_recall: 0.2381 - val_precision: 0.2381\n",
      "Epoch 9/500\n",
      "488/488 [==============================] - 0s 73us/sample - loss: 0.2422 - accuracy: 0.0000e+00 - recall: 0.2336 - precision: 0.2511 - val_loss: 0.2422 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 10/500\n",
      "488/488 [==============================] - 0s 76us/sample - loss: 0.2388 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2386 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 11/500\n",
      "488/488 [==============================] - 0s 65us/sample - loss: 0.2357 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2354 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 12/500\n",
      "488/488 [==============================] - 0s 81us/sample - loss: 0.2330 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2326 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 13/500\n",
      "488/488 [==============================] - 0s 86us/sample - loss: 0.2307 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2301 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 14/500\n",
      "488/488 [==============================] - 0s 78us/sample - loss: 0.2288 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2280 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 15/500\n",
      "488/488 [==============================] - 0s 91us/sample - loss: 0.2272 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2261 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 16/500\n",
      "488/488 [==============================] - 0s 76us/sample - loss: 0.2257 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2247 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 17/500\n",
      "488/488 [==============================] - 0s 90us/sample - loss: 0.2246 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2234 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 18/500\n",
      "488/488 [==============================] - 0s 71us/sample - loss: 0.2237 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2223 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 19/500\n",
      "488/488 [==============================] - 0s 95us/sample - loss: 0.2229 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2214 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 20/500\n",
      "488/488 [==============================] - 0s 79us/sample - loss: 0.2224 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2206 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 21/500\n",
      "488/488 [==============================] - 0s 86us/sample - loss: 0.2219 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2200 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 22/500\n",
      "488/488 [==============================] - 0s 82us/sample - loss: 0.2215 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2195 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 23/500\n",
      "488/488 [==============================] - 0s 79us/sample - loss: 0.2213 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2191 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 24/500\n",
      "488/488 [==============================] - 0s 74us/sample - loss: 0.2210 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2188 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 25/500\n",
      "488/488 [==============================] - 0s 74us/sample - loss: 0.2209 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2185 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 26/500\n",
      "488/488 [==============================] - 0s 81us/sample - loss: 0.2207 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2183 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 27/500\n",
      "488/488 [==============================] - 0s 83us/sample - loss: 0.2207 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2182 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 28/500\n",
      "488/488 [==============================] - 0s 77us/sample - loss: 0.2206 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2181 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 29/500\n",
      "488/488 [==============================] - 0s 81us/sample - loss: 0.2205 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2180 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 30/500\n",
      "488/488 [==============================] - 0s 75us/sample - loss: 0.2205 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2180 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 31/500\n",
      "488/488 [==============================] - 0s 71us/sample - loss: 0.2204 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2179 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 32/500\n",
      "488/488 [==============================] - 0s 82us/sample - loss: 0.2204 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2178 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 33/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/488 [==============================] - 0s 76us/sample - loss: 0.2204 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2177 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 34/500\n",
      "488/488 [==============================] - 0s 86us/sample - loss: 0.2204 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2177 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 35/500\n",
      "488/488 [==============================] - 0s 73us/sample - loss: 0.2203 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2176 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 36/500\n",
      "488/488 [==============================] - 0s 54us/sample - loss: 0.2203 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2176 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 37/500\n",
      "488/488 [==============================] - 0s 54us/sample - loss: 0.2203 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2176 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 38/500\n",
      "488/488 [==============================] - 0s 83us/sample - loss: 0.2202 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2175 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 39/500\n",
      "488/488 [==============================] - 0s 128us/sample - loss: 0.2202 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2174 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 40/500\n",
      "488/488 [==============================] - 0s 209us/sample - loss: 0.2201 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2174 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 41/500\n",
      "488/488 [==============================] - 0s 64us/sample - loss: 0.2201 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2173 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 42/500\n",
      "488/488 [==============================] - 0s 72us/sample - loss: 0.2200 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2173 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 43/500\n",
      "488/488 [==============================] - 0s 54us/sample - loss: 0.2200 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2172 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 44/500\n",
      "488/488 [==============================] - 0s 65us/sample - loss: 0.2199 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2171 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 45/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.2198 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2170 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 46/500\n",
      "488/488 [==============================] - 0s 64us/sample - loss: 0.2197 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2169 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 47/500\n",
      "488/488 [==============================] - 0s 57us/sample - loss: 0.2196 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2167 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 48/500\n",
      "488/488 [==============================] - 0s 69us/sample - loss: 0.2195 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2165 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 49/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.2194 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2163 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 50/500\n",
      "488/488 [==============================] - 0s 79us/sample - loss: 0.2192 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2162 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 51/500\n",
      "488/488 [==============================] - 0s 78us/sample - loss: 0.2191 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2160 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 52/500\n",
      "488/488 [==============================] - 0s 57us/sample - loss: 0.2189 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2158 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 53/500\n",
      "488/488 [==============================] - 0s 72us/sample - loss: 0.2187 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2156 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 54/500\n",
      "488/488 [==============================] - 0s 81us/sample - loss: 0.2184 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2154 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 55/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.2182 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2152 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 56/500\n",
      "488/488 [==============================] - 0s 108us/sample - loss: 0.2179 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2149 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 57/500\n",
      "488/488 [==============================] - 0s 86us/sample - loss: 0.2176 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2146 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 58/500\n",
      "488/488 [==============================] - 0s 78us/sample - loss: 0.2172 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2142 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 59/500\n",
      "488/488 [==============================] - 0s 65us/sample - loss: 0.2167 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2137 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 60/500\n",
      "488/488 [==============================] - 0s 84us/sample - loss: 0.2163 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2132 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 61/500\n",
      "488/488 [==============================] - 0s 81us/sample - loss: 0.2158 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2127 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 62/500\n",
      "488/488 [==============================] - 0s 69us/sample - loss: 0.2152 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2121 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 63/500\n",
      "488/488 [==============================] - 0s 60us/sample - loss: 0.2145 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2114 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 64/500\n",
      "488/488 [==============================] - 0s 82us/sample - loss: 0.2137 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2106 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 65/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/488 [==============================] - 0s 57us/sample - loss: 0.2129 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2099 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 66/500\n",
      "488/488 [==============================] - 0s 53us/sample - loss: 0.2119 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2091 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 67/500\n",
      "488/488 [==============================] - 0s 52us/sample - loss: 0.2109 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2080 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 68/500\n",
      "488/488 [==============================] - 0s 64us/sample - loss: 0.2098 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2069 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 69/500\n",
      "488/488 [==============================] - 0s 63us/sample - loss: 0.2085 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2056 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 70/500\n",
      "488/488 [==============================] - 0s 71us/sample - loss: 0.2071 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2042 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 71/500\n",
      "488/488 [==============================] - 0s 57us/sample - loss: 0.2056 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2027 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 72/500\n",
      "488/488 [==============================] - 0s 77us/sample - loss: 0.2039 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.2012 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 73/500\n",
      "488/488 [==============================] - 0s 53us/sample - loss: 0.2021 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.1995 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 74/500\n",
      "488/488 [==============================] - 0s 67us/sample - loss: 0.2001 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.1977 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 75/500\n",
      "488/488 [==============================] - 0s 73us/sample - loss: 0.1980 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.1957 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 76/500\n",
      "488/488 [==============================] - 0s 72us/sample - loss: 0.1958 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.1936 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 77/500\n",
      "488/488 [==============================] - 0s 60us/sample - loss: 0.1934 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.1914 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 78/500\n",
      "488/488 [==============================] - 0s 67us/sample - loss: 0.1909 - accuracy: 0.0000e+00 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.1890 - val_accuracy: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 79/500\n",
      "488/488 [==============================] - 0s 54us/sample - loss: 0.1883 - accuracy: 0.0000e+00 - recall: 0.0266 - precision: 1.0000 - val_loss: 0.1867 - val_accuracy: 0.0000e+00 - val_recall: 0.1476 - val_precision: 0.9688\n",
      "Epoch 80/500\n",
      "488/488 [==============================] - 0s 63us/sample - loss: 0.1856 - accuracy: 0.0000e+00 - recall: 0.1414 - precision: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.0000e+00 - val_recall: 0.1810 - val_precision: 0.9500\n",
      "Epoch 81/500\n",
      "488/488 [==============================] - 0s 68us/sample - loss: 0.1828 - accuracy: 0.0000e+00 - recall: 0.1967 - precision: 1.0000 - val_loss: 0.1818 - val_accuracy: 0.0000e+00 - val_recall: 0.2238 - val_precision: 0.9400\n",
      "Epoch 82/500\n",
      "488/488 [==============================] - 0s 69us/sample - loss: 0.1800 - accuracy: 0.0000e+00 - recall: 0.2193 - precision: 1.0000 - val_loss: 0.1792 - val_accuracy: 0.0000e+00 - val_recall: 0.2333 - val_precision: 0.9423\n",
      "Epoch 83/500\n",
      "488/488 [==============================] - 0s 56us/sample - loss: 0.1770 - accuracy: 0.0000e+00 - recall: 0.2480 - precision: 1.0000 - val_loss: 0.1765 - val_accuracy: 0.0000e+00 - val_recall: 0.2667 - val_precision: 0.9492\n",
      "Epoch 84/500\n",
      "488/488 [==============================] - 0s 64us/sample - loss: 0.1741 - accuracy: 0.0000e+00 - recall: 0.2602 - precision: 1.0000 - val_loss: 0.1738 - val_accuracy: 0.0000e+00 - val_recall: 0.2714 - val_precision: 0.9500\n",
      "Epoch 85/500\n",
      "488/488 [==============================] - 0s 69us/sample - loss: 0.1711 - accuracy: 0.0000e+00 - recall: 0.2705 - precision: 1.0000 - val_loss: 0.1712 - val_accuracy: 0.0000e+00 - val_recall: 0.2810 - val_precision: 0.9516\n",
      "Epoch 86/500\n",
      "488/488 [==============================] - 0s 66us/sample - loss: 0.1682 - accuracy: 0.0000e+00 - recall: 0.2787 - precision: 1.0000 - val_loss: 0.1685 - val_accuracy: 0.0000e+00 - val_recall: 0.2810 - val_precision: 0.9365\n",
      "Epoch 87/500\n",
      "488/488 [==============================] - 0s 51us/sample - loss: 0.1654 - accuracy: 0.0000e+00 - recall: 0.2992 - precision: 0.9932 - val_loss: 0.1659 - val_accuracy: 0.0000e+00 - val_recall: 0.2810 - val_precision: 0.9365\n",
      "Epoch 88/500\n",
      "488/488 [==============================] - 0s 66us/sample - loss: 0.1627 - accuracy: 0.0000e+00 - recall: 0.3115 - precision: 0.9806 - val_loss: 0.1636 - val_accuracy: 0.0000e+00 - val_recall: 0.3048 - val_precision: 0.9275\n",
      "Epoch 89/500\n",
      "488/488 [==============================] - 0s 73us/sample - loss: 0.1598 - accuracy: 0.0000e+00 - recall: 0.3156 - precision: 0.9809 - val_loss: 0.1611 - val_accuracy: 0.0000e+00 - val_recall: 0.3000 - val_precision: 0.9403\n",
      "Epoch 90/500\n",
      "488/488 [==============================] - 0s 60us/sample - loss: 0.1572 - accuracy: 0.0000e+00 - recall: 0.3197 - precision: 0.9873 - val_loss: 0.1587 - val_accuracy: 0.0000e+00 - val_recall: 0.3048 - val_precision: 0.9412\n",
      "Epoch 91/500\n",
      "488/488 [==============================] - 0s 68us/sample - loss: 0.1547 - accuracy: 0.0000e+00 - recall: 0.3176 - precision: 0.9873 - val_loss: 0.1565 - val_accuracy: 0.0000e+00 - val_recall: 0.3048 - val_precision: 0.9412\n",
      "Epoch 92/500\n",
      "488/488 [==============================] - 0s 64us/sample - loss: 0.1523 - accuracy: 0.0000e+00 - recall: 0.3197 - precision: 0.9873 - val_loss: 0.1543 - val_accuracy: 0.0000e+00 - val_recall: 0.3143 - val_precision: 0.9296\n",
      "Epoch 93/500\n",
      "488/488 [==============================] - 0s 66us/sample - loss: 0.1500 - accuracy: 0.0000e+00 - recall: 0.3258 - precision: 0.9815 - val_loss: 0.1522 - val_accuracy: 0.0000e+00 - val_recall: 0.3143 - val_precision: 0.9296\n",
      "Epoch 94/500\n",
      "488/488 [==============================] - 0s 60us/sample - loss: 0.1477 - accuracy: 0.0000e+00 - recall: 0.3258 - precision: 0.9755 - val_loss: 0.1502 - val_accuracy: 0.0000e+00 - val_recall: 0.3190 - val_precision: 0.9306\n",
      "Epoch 95/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.1456 - accuracy: 0.0000e+00 - recall: 0.3279 - precision: 0.9756 - val_loss: 0.1483 - val_accuracy: 0.0000e+00 - val_recall: 0.3190 - val_precision: 0.9306\n",
      "Epoch 96/500\n",
      "488/488 [==============================] - 0s 69us/sample - loss: 0.1436 - accuracy: 0.0000e+00 - recall: 0.3320 - precision: 0.9759 - val_loss: 0.1466 - val_accuracy: 0.0000e+00 - val_recall: 0.3190 - val_precision: 0.9306\n",
      "Epoch 97/500\n",
      "488/488 [==============================] - 0s 53us/sample - loss: 0.1417 - accuracy: 0.0000e+00 - recall: 0.3361 - precision: 0.8962 - val_loss: 0.1449 - val_accuracy: 0.0000e+00 - val_recall: 0.3619 - val_precision: 0.5891\n",
      "Epoch 98/500\n",
      "488/488 [==============================] - 0s 67us/sample - loss: 0.1399 - accuracy: 0.0000e+00 - recall: 0.4098 - precision: 0.5917 - val_loss: 0.1433 - val_accuracy: 0.0000e+00 - val_recall: 0.4810 - val_precision: 0.6558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/500\n",
      "488/488 [==============================] - 0s 63us/sample - loss: 0.1383 - accuracy: 0.0000e+00 - recall: 0.5123 - precision: 0.6427 - val_loss: 0.1418 - val_accuracy: 0.0000e+00 - val_recall: 0.5619 - val_precision: 0.6901\n",
      "Epoch 100/500\n",
      "488/488 [==============================] - 0s 63us/sample - loss: 0.1367 - accuracy: 0.0000e+00 - recall: 0.5471 - precision: 0.6560 - val_loss: 0.1404 - val_accuracy: 0.0000e+00 - val_recall: 0.5857 - val_precision: 0.6989\n",
      "Epoch 101/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.1353 - accuracy: 0.0000e+00 - recall: 0.5840 - precision: 0.6706 - val_loss: 0.1391 - val_accuracy: 0.0000e+00 - val_recall: 0.6095 - val_precision: 0.7072\n",
      "Epoch 102/500\n",
      "488/488 [==============================] - 0s 56us/sample - loss: 0.1340 - accuracy: 0.0000e+00 - recall: 0.6045 - precision: 0.6782 - val_loss: 0.1379 - val_accuracy: 0.0000e+00 - val_recall: 0.6286 - val_precision: 0.7097\n",
      "Epoch 103/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.1327 - accuracy: 0.0000e+00 - recall: 0.6148 - precision: 0.6818 - val_loss: 0.1367 - val_accuracy: 0.0000e+00 - val_recall: 0.6286 - val_precision: 0.7097\n",
      "Epoch 104/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.1315 - accuracy: 0.0000e+00 - recall: 0.6209 - precision: 0.6840 - val_loss: 0.1356 - val_accuracy: 0.0000e+00 - val_recall: 0.6333 - val_precision: 0.7112\n",
      "Epoch 105/500\n",
      "488/488 [==============================] - 0s 68us/sample - loss: 0.1304 - accuracy: 0.0000e+00 - recall: 0.6250 - precision: 0.6854 - val_loss: 0.1347 - val_accuracy: 0.0000e+00 - val_recall: 0.6429 - val_precision: 0.7143\n",
      "Epoch 106/500\n",
      "488/488 [==============================] - 0s 60us/sample - loss: 0.1294 - accuracy: 0.0000e+00 - recall: 0.6291 - precision: 0.6868 - val_loss: 0.1337 - val_accuracy: 0.0000e+00 - val_recall: 0.6429 - val_precision: 0.7143\n",
      "Epoch 107/500\n",
      "488/488 [==============================] - 0s 69us/sample - loss: 0.1284 - accuracy: 0.0000e+00 - recall: 0.6414 - precision: 0.6925 - val_loss: 0.1330 - val_accuracy: 0.0000e+00 - val_recall: 0.6429 - val_precision: 0.7143\n",
      "Epoch 108/500\n",
      "488/488 [==============================] - 0s 63us/sample - loss: 0.1276 - accuracy: 0.0000e+00 - recall: 0.6475 - precision: 0.6960 - val_loss: 0.1321 - val_accuracy: 0.0000e+00 - val_recall: 0.6429 - val_precision: 0.7143\n",
      "Epoch 109/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.1267 - accuracy: 0.0000e+00 - recall: 0.6475 - precision: 0.6945 - val_loss: 0.1314 - val_accuracy: 0.0000e+00 - val_recall: 0.6476 - val_precision: 0.7158\n",
      "Epoch 110/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.1259 - accuracy: 0.0000e+00 - recall: 0.6455 - precision: 0.6938 - val_loss: 0.1307 - val_accuracy: 0.0000e+00 - val_recall: 0.6476 - val_precision: 0.7158\n",
      "Epoch 111/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.1252 - accuracy: 0.0000e+00 - recall: 0.6434 - precision: 0.6901 - val_loss: 0.1300 - val_accuracy: 0.0000e+00 - val_recall: 0.6476 - val_precision: 0.7158\n",
      "Epoch 112/500\n",
      "488/488 [==============================] - 0s 64us/sample - loss: 0.1246 - accuracy: 0.0000e+00 - recall: 0.6455 - precision: 0.6923 - val_loss: 0.1293 - val_accuracy: 0.0000e+00 - val_recall: 0.6571 - val_precision: 0.7188\n",
      "Epoch 113/500\n",
      "488/488 [==============================] - 0s 63us/sample - loss: 0.1238 - accuracy: 0.0000e+00 - recall: 0.6496 - precision: 0.6967 - val_loss: 0.1287 - val_accuracy: 0.0000e+00 - val_recall: 0.6524 - val_precision: 0.7173\n",
      "Epoch 114/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.1232 - accuracy: 0.0000e+00 - recall: 0.6516 - precision: 0.6958 - val_loss: 0.1282 - val_accuracy: 0.0000e+00 - val_recall: 0.6571 - val_precision: 0.7188\n",
      "Epoch 115/500\n",
      "488/488 [==============================] - 0s 65us/sample - loss: 0.1226 - accuracy: 0.0000e+00 - recall: 0.6516 - precision: 0.6958 - val_loss: 0.1277 - val_accuracy: 0.0000e+00 - val_recall: 0.6571 - val_precision: 0.7188\n",
      "Epoch 116/500\n",
      "488/488 [==============================] - 0s 56us/sample - loss: 0.1221 - accuracy: 0.0000e+00 - recall: 0.6557 - precision: 0.6972 - val_loss: 0.1272 - val_accuracy: 0.0000e+00 - val_recall: 0.6571 - val_precision: 0.7188\n",
      "Epoch 117/500\n",
      "488/488 [==============================] - 0s 61us/sample - loss: 0.1216 - accuracy: 0.0000e+00 - recall: 0.6557 - precision: 0.6972 - val_loss: 0.1269 - val_accuracy: 0.0000e+00 - val_recall: 0.6619 - val_precision: 0.7202\n",
      "Epoch 118/500\n",
      "488/488 [==============================] - 0s 71us/sample - loss: 0.1211 - accuracy: 0.0000e+00 - recall: 0.6557 - precision: 0.6987 - val_loss: 0.1265 - val_accuracy: 0.0000e+00 - val_recall: 0.6619 - val_precision: 0.7202\n",
      "Epoch 119/500\n",
      "488/488 [==============================] - 0s 72us/sample - loss: 0.1206 - accuracy: 0.0000e+00 - recall: 0.6557 - precision: 0.6987 - val_loss: 0.1262 - val_accuracy: 0.0000e+00 - val_recall: 0.6619 - val_precision: 0.7202\n",
      "Epoch 120/500\n",
      "488/488 [==============================] - 0s 53us/sample - loss: 0.1202 - accuracy: 0.0000e+00 - recall: 0.6557 - precision: 0.6987 - val_loss: 0.1257 - val_accuracy: 0.0000e+00 - val_recall: 0.6667 - val_precision: 0.7216\n",
      "Epoch 121/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.1198 - accuracy: 0.0000e+00 - recall: 0.6557 - precision: 0.6987 - val_loss: 0.1254 - val_accuracy: 0.0000e+00 - val_recall: 0.6619 - val_precision: 0.7202\n",
      "Epoch 122/500\n",
      "488/488 [==============================] - 0s 64us/sample - loss: 0.1194 - accuracy: 0.0000e+00 - recall: 0.6557 - precision: 0.6987 - val_loss: 0.1250 - val_accuracy: 0.0000e+00 - val_recall: 0.6762 - val_precision: 0.7245\n",
      "Epoch 123/500\n",
      "488/488 [==============================] - 0s 52us/sample - loss: 0.1190 - accuracy: 0.0000e+00 - recall: 0.6578 - precision: 0.6993 - val_loss: 0.1245 - val_accuracy: 0.0000e+00 - val_recall: 0.6905 - val_precision: 0.7286\n",
      "Epoch 124/500\n",
      "488/488 [==============================] - 0s 68us/sample - loss: 0.1187 - accuracy: 0.0000e+00 - recall: 0.6639 - precision: 0.7013 - val_loss: 0.1239 - val_accuracy: 0.0000e+00 - val_recall: 0.6905 - val_precision: 0.7286\n",
      "Epoch 125/500\n",
      "488/488 [==============================] - 0s 56us/sample - loss: 0.1183 - accuracy: 0.0000e+00 - recall: 0.6639 - precision: 0.7013 - val_loss: 0.1236 - val_accuracy: 0.0000e+00 - val_recall: 0.6905 - val_precision: 0.7286\n",
      "Epoch 126/500\n",
      "488/488 [==============================] - 0s 67us/sample - loss: 0.1179 - accuracy: 0.0000e+00 - recall: 0.6680 - precision: 0.7026 - val_loss: 0.1233 - val_accuracy: 0.0000e+00 - val_recall: 0.6905 - val_precision: 0.7286\n",
      "Epoch 127/500\n",
      "488/488 [==============================] - 0s 72us/sample - loss: 0.1176 - accuracy: 0.0000e+00 - recall: 0.6701 - precision: 0.7032 - val_loss: 0.1231 - val_accuracy: 0.0000e+00 - val_recall: 0.6857 - val_precision: 0.7273\n",
      "Epoch 128/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.1174 - accuracy: 0.0000e+00 - recall: 0.6762 - precision: 0.7051 - val_loss: 0.1229 - val_accuracy: 0.0000e+00 - val_recall: 0.6857 - val_precision: 0.7273\n",
      "Epoch 129/500\n",
      "488/488 [==============================] - 0s 52us/sample - loss: 0.1170 - accuracy: 0.0000e+00 - recall: 0.6701 - precision: 0.7032 - val_loss: 0.1226 - val_accuracy: 0.0000e+00 - val_recall: 0.6952 - val_precision: 0.7300\n",
      "Epoch 130/500\n",
      "488/488 [==============================] - 0s 60us/sample - loss: 0.1168 - accuracy: 0.0000e+00 - recall: 0.6680 - precision: 0.7026 - val_loss: 0.1226 - val_accuracy: 0.0000e+00 - val_recall: 0.6952 - val_precision: 0.7300\n",
      "Epoch 131/500\n",
      "488/488 [==============================] - 0s 63us/sample - loss: 0.1166 - accuracy: 0.0000e+00 - recall: 0.6619 - precision: 0.6976 - val_loss: 0.1224 - val_accuracy: 0.0000e+00 - val_recall: 0.6952 - val_precision: 0.7300\n",
      "Epoch 132/500\n",
      "488/488 [==============================] - 0s 69us/sample - loss: 0.1162 - accuracy: 0.0000e+00 - recall: 0.6680 - precision: 0.7026 - val_loss: 0.1219 - val_accuracy: 0.0000e+00 - val_recall: 0.6952 - val_precision: 0.7337\n",
      "Epoch 133/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/488 [==============================] - 0s 53us/sample - loss: 0.1159 - accuracy: 0.0000e+00 - recall: 0.6721 - precision: 0.7054 - val_loss: 0.1216 - val_accuracy: 0.0000e+00 - val_recall: 0.6857 - val_precision: 0.7310\n",
      "Epoch 134/500\n",
      "488/488 [==============================] - 0s 70us/sample - loss: 0.1158 - accuracy: 0.0000e+00 - recall: 0.6742 - precision: 0.7060 - val_loss: 0.1214 - val_accuracy: 0.0000e+00 - val_recall: 0.6857 - val_precision: 0.7310\n",
      "Epoch 135/500\n",
      "488/488 [==============================] - 0s 57us/sample - loss: 0.1155 - accuracy: 0.0000e+00 - recall: 0.6742 - precision: 0.7060 - val_loss: 0.1211 - val_accuracy: 0.0000e+00 - val_recall: 0.6952 - val_precision: 0.7337\n",
      "Epoch 136/500\n",
      "488/488 [==============================] - 0s 56us/sample - loss: 0.1152 - accuracy: 0.0000e+00 - recall: 0.6721 - precision: 0.7054 - val_loss: 0.1207 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7350\n",
      "Epoch 137/500\n",
      "488/488 [==============================] - 0s 61us/sample - loss: 0.1150 - accuracy: 0.0000e+00 - recall: 0.6721 - precision: 0.7054 - val_loss: 0.1204 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7350\n",
      "Epoch 138/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.1148 - accuracy: 0.0000e+00 - recall: 0.6742 - precision: 0.7030 - val_loss: 0.1201 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7350\n",
      "Epoch 139/500\n",
      "488/488 [==============================] - 0s 69us/sample - loss: 0.1146 - accuracy: 0.0000e+00 - recall: 0.6762 - precision: 0.7066 - val_loss: 0.1199 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7350\n",
      "Epoch 140/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.1144 - accuracy: 0.0000e+00 - recall: 0.6762 - precision: 0.7066 - val_loss: 0.1197 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7350\n",
      "Epoch 141/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.1142 - accuracy: 0.0000e+00 - recall: 0.6762 - precision: 0.7066 - val_loss: 0.1196 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7350\n",
      "Epoch 142/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.1140 - accuracy: 0.0000e+00 - recall: 0.6762 - precision: 0.7066 - val_loss: 0.1196 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7363\n",
      "Epoch 143/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.1138 - accuracy: 0.0000e+00 - recall: 0.6803 - precision: 0.7079 - val_loss: 0.1194 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7363\n",
      "Epoch 144/500\n",
      "488/488 [==============================] - 0s 64us/sample - loss: 0.1136 - accuracy: 0.0000e+00 - recall: 0.6783 - precision: 0.7073 - val_loss: 0.1193 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7350\n",
      "Epoch 145/500\n",
      "488/488 [==============================] - 0s 73us/sample - loss: 0.1135 - accuracy: 0.0000e+00 - recall: 0.6803 - precision: 0.7079 - val_loss: 0.1192 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7350\n",
      "Epoch 146/500\n",
      "488/488 [==============================] - 0s 66us/sample - loss: 0.1133 - accuracy: 0.0000e+00 - recall: 0.6824 - precision: 0.7085 - val_loss: 0.1192 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7350\n",
      "Epoch 147/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.1131 - accuracy: 0.0000e+00 - recall: 0.6803 - precision: 0.7079 - val_loss: 0.1191 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7350\n",
      "Epoch 148/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.1129 - accuracy: 0.0000e+00 - recall: 0.6803 - precision: 0.7079 - val_loss: 0.1191 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7350\n",
      "Epoch 149/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.1128 - accuracy: 0.0000e+00 - recall: 0.6783 - precision: 0.7073 - val_loss: 0.1191 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7350\n",
      "Epoch 150/500\n",
      "488/488 [==============================] - 0s 65us/sample - loss: 0.1126 - accuracy: 0.0000e+00 - recall: 0.6783 - precision: 0.7073 - val_loss: 0.1190 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7350\n",
      "Epoch 151/500\n",
      "488/488 [==============================] - 0s 57us/sample - loss: 0.1125 - accuracy: 0.0000e+00 - recall: 0.6762 - precision: 0.7066 - val_loss: 0.1188 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7350\n",
      "Epoch 152/500\n",
      "488/488 [==============================] - 0s 71us/sample - loss: 0.1124 - accuracy: 0.0000e+00 - recall: 0.6762 - precision: 0.7066 - val_loss: 0.1187 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7350\n",
      "Epoch 153/500\n",
      "488/488 [==============================] - 0s 69us/sample - loss: 0.1122 - accuracy: 0.0000e+00 - recall: 0.6803 - precision: 0.7079 - val_loss: 0.1186 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7350\n",
      "Epoch 154/500\n",
      "488/488 [==============================] - 0s 53us/sample - loss: 0.1121 - accuracy: 0.0000e+00 - recall: 0.6865 - precision: 0.7097 - val_loss: 0.1184 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7350\n",
      "Epoch 155/500\n",
      "488/488 [==============================] - 0s 66us/sample - loss: 0.1120 - accuracy: 0.0000e+00 - recall: 0.6865 - precision: 0.7097 - val_loss: 0.1183 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7350\n",
      "Epoch 156/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.1118 - accuracy: 0.0000e+00 - recall: 0.6865 - precision: 0.7097 - val_loss: 0.1182 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7350\n",
      "Epoch 157/500\n",
      "488/488 [==============================] - 0s 64us/sample - loss: 0.1116 - accuracy: 0.0000e+00 - recall: 0.6865 - precision: 0.7097 - val_loss: 0.1181 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7363\n",
      "Epoch 158/500\n",
      "488/488 [==============================] - 0s 63us/sample - loss: 0.1115 - accuracy: 0.0000e+00 - recall: 0.6865 - precision: 0.7097 - val_loss: 0.1180 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7363\n",
      "Epoch 159/500\n",
      "488/488 [==============================] - 0s 68us/sample - loss: 0.1114 - accuracy: 0.0000e+00 - recall: 0.6865 - precision: 0.7097 - val_loss: 0.1179 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7363\n",
      "Epoch 160/500\n",
      "488/488 [==============================] - 0s 52us/sample - loss: 0.1112 - accuracy: 0.0000e+00 - recall: 0.6865 - precision: 0.7097 - val_loss: 0.1178 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7363\n",
      "Epoch 161/500\n",
      "488/488 [==============================] - 0s 55us/sample - loss: 0.1111 - accuracy: 0.0000e+00 - recall: 0.6865 - precision: 0.7097 - val_loss: 0.1176 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7363\n",
      "Epoch 162/500\n",
      "488/488 [==============================] - 0s 77us/sample - loss: 0.1110 - accuracy: 0.0000e+00 - recall: 0.6865 - precision: 0.7097 - val_loss: 0.1175 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7363\n",
      "Epoch 163/500\n",
      "488/488 [==============================] - 0s 67us/sample - loss: 0.1109 - accuracy: 0.0000e+00 - recall: 0.6865 - precision: 0.7097 - val_loss: 0.1175 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7363\n",
      "Epoch 164/500\n",
      "488/488 [==============================] - 0s 64us/sample - loss: 0.1107 - accuracy: 0.0000e+00 - recall: 0.6865 - precision: 0.7097 - val_loss: 0.1174 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7363\n",
      "Epoch 165/500\n",
      "488/488 [==============================] - 0s 65us/sample - loss: 0.1106 - accuracy: 0.0000e+00 - recall: 0.6865 - precision: 0.7097 - val_loss: 0.1172 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7363\n",
      "Epoch 166/500\n",
      "488/488 [==============================] - 0s 77us/sample - loss: 0.1105 - accuracy: 0.0000e+00 - recall: 0.6906 - precision: 0.7110 - val_loss: 0.1170 - val_accuracy: 0.0000e+00 - val_recall: 0.7095 - val_precision: 0.7376\n",
      "Epoch 167/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/488 [==============================] - 0s 56us/sample - loss: 0.1104 - accuracy: 0.0000e+00 - recall: 0.6906 - precision: 0.7110 - val_loss: 0.1168 - val_accuracy: 0.0000e+00 - val_recall: 0.7095 - val_precision: 0.7376\n",
      "Epoch 168/500\n",
      "488/488 [==============================] - 0s 56us/sample - loss: 0.1103 - accuracy: 0.0000e+00 - recall: 0.6947 - precision: 0.7122 - val_loss: 0.1167 - val_accuracy: 0.0000e+00 - val_recall: 0.7095 - val_precision: 0.7376\n",
      "Epoch 169/500\n",
      "488/488 [==============================] - 0s 53us/sample - loss: 0.1101 - accuracy: 0.0000e+00 - recall: 0.6947 - precision: 0.7122 - val_loss: 0.1166 - val_accuracy: 0.0000e+00 - val_recall: 0.7095 - val_precision: 0.7376\n",
      "Epoch 170/500\n",
      "488/488 [==============================] - 0s 57us/sample - loss: 0.1100 - accuracy: 0.0000e+00 - recall: 0.6906 - precision: 0.7110 - val_loss: 0.1166 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7363\n",
      "Epoch 171/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.1099 - accuracy: 0.0000e+00 - recall: 0.6906 - precision: 0.7110 - val_loss: 0.1165 - val_accuracy: 0.0000e+00 - val_recall: 0.7095 - val_precision: 0.7413\n",
      "Epoch 172/500\n",
      "488/488 [==============================] - 0s 60us/sample - loss: 0.1098 - accuracy: 0.0000e+00 - recall: 0.6947 - precision: 0.7122 - val_loss: 0.1164 - val_accuracy: 0.0000e+00 - val_recall: 0.7095 - val_precision: 0.7413\n",
      "Epoch 173/500\n",
      "488/488 [==============================] - 0s 69us/sample - loss: 0.1097 - accuracy: 0.0000e+00 - recall: 0.6947 - precision: 0.7122 - val_loss: 0.1163 - val_accuracy: 0.0000e+00 - val_recall: 0.7095 - val_precision: 0.7413\n",
      "Epoch 174/500\n",
      "488/488 [==============================] - 0s 69us/sample - loss: 0.1095 - accuracy: 0.0000e+00 - recall: 0.6926 - precision: 0.7116 - val_loss: 0.1162 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7350\n",
      "Epoch 175/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.1094 - accuracy: 0.0000e+00 - recall: 0.6906 - precision: 0.7110 - val_loss: 0.1162 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7313\n",
      "Epoch 176/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.1093 - accuracy: 0.0000e+00 - recall: 0.6906 - precision: 0.7110 - val_loss: 0.1161 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7313\n",
      "Epoch 177/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.1092 - accuracy: 0.0000e+00 - recall: 0.6906 - precision: 0.7110 - val_loss: 0.1158 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7363\n",
      "Epoch 178/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.1091 - accuracy: 0.0000e+00 - recall: 0.6926 - precision: 0.7116 - val_loss: 0.1157 - val_accuracy: 0.0000e+00 - val_recall: 0.7095 - val_precision: 0.7413\n",
      "Epoch 179/500\n",
      "488/488 [==============================] - 0s 66us/sample - loss: 0.1090 - accuracy: 0.0000e+00 - recall: 0.6926 - precision: 0.7116 - val_loss: 0.1156 - val_accuracy: 0.0000e+00 - val_recall: 0.7095 - val_precision: 0.7413\n",
      "Epoch 180/500\n",
      "488/488 [==============================] - 0s 63us/sample - loss: 0.1089 - accuracy: 0.0000e+00 - recall: 0.6947 - precision: 0.7122 - val_loss: 0.1155 - val_accuracy: 0.0000e+00 - val_recall: 0.7095 - val_precision: 0.7413\n",
      "Epoch 181/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.1087 - accuracy: 0.0000e+00 - recall: 0.6947 - precision: 0.7122 - val_loss: 0.1154 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7327\n",
      "Epoch 182/500\n",
      "488/488 [==============================] - 0s 61us/sample - loss: 0.1086 - accuracy: 0.0000e+00 - recall: 0.6926 - precision: 0.7116 - val_loss: 0.1153 - val_accuracy: 0.0000e+00 - val_recall: 0.7095 - val_precision: 0.7340\n",
      "Epoch 183/500\n",
      "488/488 [==============================] - 0s 60us/sample - loss: 0.1085 - accuracy: 0.0000e+00 - recall: 0.6947 - precision: 0.7122 - val_loss: 0.1151 - val_accuracy: 0.0000e+00 - val_recall: 0.7095 - val_precision: 0.7413\n",
      "Epoch 184/500\n",
      "488/488 [==============================] - 0s 64us/sample - loss: 0.1083 - accuracy: 0.0000e+00 - recall: 0.6947 - precision: 0.7122 - val_loss: 0.1150 - val_accuracy: 0.0000e+00 - val_recall: 0.7095 - val_precision: 0.7340\n",
      "Epoch 185/500\n",
      "488/488 [==============================] - 0s 66us/sample - loss: 0.1082 - accuracy: 0.0000e+00 - recall: 0.6947 - precision: 0.7122 - val_loss: 0.1149 - val_accuracy: 0.0000e+00 - val_recall: 0.7095 - val_precision: 0.7340\n",
      "Epoch 186/500\n",
      "488/488 [==============================] - 0s 73us/sample - loss: 0.1081 - accuracy: 0.0000e+00 - recall: 0.6947 - precision: 0.7122 - val_loss: 0.1148 - val_accuracy: 0.0000e+00 - val_recall: 0.7095 - val_precision: 0.7376\n",
      "Epoch 187/500\n",
      "488/488 [==============================] - 0s 68us/sample - loss: 0.1080 - accuracy: 0.0000e+00 - recall: 0.6947 - precision: 0.7122 - val_loss: 0.1147 - val_accuracy: 0.0000e+00 - val_recall: 0.7095 - val_precision: 0.7340\n",
      "Epoch 188/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.1079 - accuracy: 0.0000e+00 - recall: 0.6926 - precision: 0.7116 - val_loss: 0.1147 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7327\n",
      "Epoch 189/500\n",
      "488/488 [==============================] - 0s 64us/sample - loss: 0.1077 - accuracy: 0.0000e+00 - recall: 0.6926 - precision: 0.7116 - val_loss: 0.1146 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7363\n",
      "Epoch 190/500\n",
      "488/488 [==============================] - 0s 52us/sample - loss: 0.1076 - accuracy: 0.0000e+00 - recall: 0.6926 - precision: 0.7116 - val_loss: 0.1145 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7363\n",
      "Epoch 191/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.1074 - accuracy: 0.0000e+00 - recall: 0.6926 - precision: 0.7116 - val_loss: 0.1143 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7363\n",
      "Epoch 192/500\n",
      "488/488 [==============================] - 0s 55us/sample - loss: 0.1073 - accuracy: 0.0000e+00 - recall: 0.6926 - precision: 0.7116 - val_loss: 0.1141 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7327\n",
      "Epoch 193/500\n",
      "488/488 [==============================] - 0s 60us/sample - loss: 0.1072 - accuracy: 0.0000e+00 - recall: 0.6926 - precision: 0.7116 - val_loss: 0.1142 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7327\n",
      "Epoch 194/500\n",
      "488/488 [==============================] - 0s 52us/sample - loss: 0.1071 - accuracy: 0.0000e+00 - recall: 0.6926 - precision: 0.7116 - val_loss: 0.1140 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7327\n",
      "Epoch 195/500\n",
      "488/488 [==============================] - 0s 67us/sample - loss: 0.1069 - accuracy: 0.0000e+00 - recall: 0.6926 - precision: 0.7116 - val_loss: 0.1137 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7363\n",
      "Epoch 196/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.1068 - accuracy: 0.0000e+00 - recall: 0.7008 - precision: 0.7140 - val_loss: 0.1135 - val_accuracy: 0.0000e+00 - val_recall: 0.7095 - val_precision: 0.7376\n",
      "Epoch 197/500\n",
      "488/488 [==============================] - 0s 64us/sample - loss: 0.1066 - accuracy: 0.0000e+00 - recall: 0.7008 - precision: 0.7140 - val_loss: 0.1135 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7363\n",
      "Epoch 198/500\n",
      "488/488 [==============================] - 0s 68us/sample - loss: 0.1064 - accuracy: 0.0000e+00 - recall: 0.6967 - precision: 0.7128 - val_loss: 0.1136 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7363\n",
      "Epoch 199/500\n",
      "488/488 [==============================] - 0s 70us/sample - loss: 0.1063 - accuracy: 0.0000e+00 - recall: 0.6947 - precision: 0.7122 - val_loss: 0.1135 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7363\n",
      "Epoch 200/500\n",
      "488/488 [==============================] - 0s 53us/sample - loss: 0.1061 - accuracy: 0.0000e+00 - recall: 0.6967 - precision: 0.7128 - val_loss: 0.1133 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7363\n",
      "Epoch 201/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/488 [==============================] - 0s 62us/sample - loss: 0.1059 - accuracy: 0.0000e+00 - recall: 0.6988 - precision: 0.7134 - val_loss: 0.1131 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7363\n",
      "Epoch 202/500\n",
      "488/488 [==============================] - 0s 76us/sample - loss: 0.1058 - accuracy: 0.0000e+00 - recall: 0.7008 - precision: 0.7140 - val_loss: 0.1129 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7350\n",
      "Epoch 203/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.1056 - accuracy: 0.0000e+00 - recall: 0.7008 - precision: 0.7140 - val_loss: 0.1129 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7350\n",
      "Epoch 204/500\n",
      "488/488 [==============================] - 0s 61us/sample - loss: 0.1054 - accuracy: 0.0000e+00 - recall: 0.6967 - precision: 0.7128 - val_loss: 0.1130 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7313\n",
      "Epoch 205/500\n",
      "488/488 [==============================] - 0s 68us/sample - loss: 0.1052 - accuracy: 0.0000e+00 - recall: 0.6947 - precision: 0.7122 - val_loss: 0.1129 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7350\n",
      "Epoch 206/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.1050 - accuracy: 0.0000e+00 - recall: 0.6988 - precision: 0.7134 - val_loss: 0.1129 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7350\n",
      "Epoch 207/500\n",
      "488/488 [==============================] - 0s 54us/sample - loss: 0.1048 - accuracy: 0.0000e+00 - recall: 0.6988 - precision: 0.7134 - val_loss: 0.1125 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7350\n",
      "Epoch 208/500\n",
      "488/488 [==============================] - 0s 63us/sample - loss: 0.1046 - accuracy: 0.0000e+00 - recall: 0.7008 - precision: 0.7140 - val_loss: 0.1124 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7350\n",
      "Epoch 209/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.1044 - accuracy: 0.0000e+00 - recall: 0.7049 - precision: 0.7152 - val_loss: 0.1122 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7363\n",
      "Epoch 210/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.1042 - accuracy: 0.0000e+00 - recall: 0.7070 - precision: 0.7158 - val_loss: 0.1121 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7363\n",
      "Epoch 211/500\n",
      "488/488 [==============================] - 0s 56us/sample - loss: 0.1039 - accuracy: 0.0000e+00 - recall: 0.7049 - precision: 0.7152 - val_loss: 0.1123 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7313\n",
      "Epoch 212/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.1037 - accuracy: 0.0000e+00 - recall: 0.7008 - precision: 0.7140 - val_loss: 0.1121 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7277\n",
      "Epoch 213/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.1034 - accuracy: 0.0000e+00 - recall: 0.6988 - precision: 0.7134 - val_loss: 0.1118 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7277\n",
      "Epoch 214/500\n",
      "488/488 [==============================] - 0s 69us/sample - loss: 0.1032 - accuracy: 0.0000e+00 - recall: 0.6988 - precision: 0.7134 - val_loss: 0.1114 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7313\n",
      "Epoch 215/500\n",
      "488/488 [==============================] - 0s 68us/sample - loss: 0.1028 - accuracy: 0.0000e+00 - recall: 0.7049 - precision: 0.7152 - val_loss: 0.1107 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7363\n",
      "Epoch 216/500\n",
      "488/488 [==============================] - 0s 64us/sample - loss: 0.1026 - accuracy: 0.0000e+00 - recall: 0.7111 - precision: 0.7169 - val_loss: 0.1104 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7363\n",
      "Epoch 217/500\n",
      "488/488 [==============================] - 0s 55us/sample - loss: 0.1023 - accuracy: 0.0000e+00 - recall: 0.7111 - precision: 0.7169 - val_loss: 0.1103 - val_accuracy: 0.0000e+00 - val_recall: 0.7048 - val_precision: 0.7363\n",
      "Epoch 218/500\n",
      "488/488 [==============================] - 0s 74us/sample - loss: 0.1020 - accuracy: 0.0000e+00 - recall: 0.7111 - precision: 0.7169 - val_loss: 0.1105 - val_accuracy: 0.0000e+00 - val_recall: 0.7000 - val_precision: 0.7313\n",
      "Epoch 219/500\n",
      "488/488 [==============================] - 0s 61us/sample - loss: 0.1017 - accuracy: 0.0000e+00 - recall: 0.7029 - precision: 0.7146 - val_loss: 0.1104 - val_accuracy: 0.0000e+00 - val_recall: 0.7095 - val_precision: 0.7304\n",
      "Epoch 220/500\n",
      "488/488 [==============================] - 0s 65us/sample - loss: 0.1013 - accuracy: 0.0000e+00 - recall: 0.7008 - precision: 0.7140 - val_loss: 0.1096 - val_accuracy: 0.0000e+00 - val_recall: 0.7095 - val_precision: 0.7340\n",
      "Epoch 221/500\n",
      "488/488 [==============================] - 0s 52us/sample - loss: 0.1009 - accuracy: 0.0000e+00 - recall: 0.7090 - precision: 0.7164 - val_loss: 0.1090 - val_accuracy: 0.0000e+00 - val_recall: 0.7095 - val_precision: 0.7376\n",
      "Epoch 222/500\n",
      "488/488 [==============================] - 0s 61us/sample - loss: 0.1006 - accuracy: 0.0000e+00 - recall: 0.7111 - precision: 0.7169 - val_loss: 0.1087 - val_accuracy: 0.0000e+00 - val_recall: 0.7095 - val_precision: 0.7376\n",
      "Epoch 223/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.1001 - accuracy: 0.0000e+00 - recall: 0.7172 - precision: 0.7187 - val_loss: 0.1085 - val_accuracy: 0.0000e+00 - val_recall: 0.7143 - val_precision: 0.7353\n",
      "Epoch 224/500\n",
      "488/488 [==============================] - 0s 65us/sample - loss: 0.0998 - accuracy: 0.0000e+00 - recall: 0.7049 - precision: 0.7152 - val_loss: 0.1082 - val_accuracy: 0.0000e+00 - val_recall: 0.7143 - val_precision: 0.7317\n",
      "Epoch 225/500\n",
      "488/488 [==============================] - 0s 64us/sample - loss: 0.0993 - accuracy: 0.0000e+00 - recall: 0.7029 - precision: 0.7146 - val_loss: 0.1072 - val_accuracy: 0.0000e+00 - val_recall: 0.7143 - val_precision: 0.7389\n",
      "Epoch 226/500\n",
      "488/488 [==============================] - 0s 55us/sample - loss: 0.0989 - accuracy: 0.0000e+00 - recall: 0.7357 - precision: 0.7238 - val_loss: 0.1065 - val_accuracy: 0.0000e+00 - val_recall: 0.7905 - val_precision: 0.7580\n",
      "Epoch 227/500\n",
      "488/488 [==============================] - 0s 83us/sample - loss: 0.0985 - accuracy: 0.0000e+00 - recall: 0.8135 - precision: 0.7434 - val_loss: 0.1062 - val_accuracy: 0.0000e+00 - val_recall: 0.8429 - val_precision: 0.7696\n",
      "Epoch 228/500\n",
      "488/488 [==============================] - 0s 64us/sample - loss: 0.0980 - accuracy: 0.0000e+00 - recall: 0.8566 - precision: 0.7532 - val_loss: 0.1062 - val_accuracy: 0.0000e+00 - val_recall: 0.8619 - val_precision: 0.7702\n",
      "Epoch 229/500\n",
      "488/488 [==============================] - 0s 50us/sample - loss: 0.0975 - accuracy: 0.0000e+00 - recall: 0.8955 - precision: 0.7613 - val_loss: 0.1061 - val_accuracy: 0.0000e+00 - val_recall: 0.9000 - val_precision: 0.7778\n",
      "Epoch 230/500\n",
      "488/488 [==============================] - 0s 61us/sample - loss: 0.0969 - accuracy: 0.0000e+00 - recall: 0.9488 - precision: 0.7691 - val_loss: 0.1053 - val_accuracy: 0.0000e+00 - val_recall: 0.9286 - val_precision: 0.7738\n",
      "Epoch 231/500\n",
      "488/488 [==============================] - 0s 66us/sample - loss: 0.0963 - accuracy: 0.0000e+00 - recall: 0.9754 - precision: 0.7556 - val_loss: 0.1047 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.7654\n",
      "Epoch 232/500\n",
      "488/488 [==============================] - 0s 53us/sample - loss: 0.0958 - accuracy: 0.0000e+00 - recall: 0.9816 - precision: 0.7415 - val_loss: 0.1041 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.7625\n",
      "Epoch 233/500\n",
      "488/488 [==============================] - 0s 57us/sample - loss: 0.0951 - accuracy: 0.0000e+00 - recall: 0.9836 - precision: 0.7385 - val_loss: 0.1038 - val_accuracy: 0.0000e+00 - val_recall: 0.9381 - val_precision: 0.7577\n",
      "Epoch 234/500\n",
      "488/488 [==============================] - 0s 67us/sample - loss: 0.0944 - accuracy: 0.0000e+00 - recall: 0.9816 - precision: 0.7369 - val_loss: 0.1035 - val_accuracy: 0.0000e+00 - val_recall: 0.9333 - val_precision: 0.7568\n",
      "Epoch 235/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/488 [==============================] - 0s 61us/sample - loss: 0.0938 - accuracy: 0.0000e+00 - recall: 0.9734 - precision: 0.7410 - val_loss: 0.1026 - val_accuracy: 0.0000e+00 - val_recall: 0.9286 - val_precision: 0.7558\n",
      "Epoch 236/500\n",
      "488/488 [==============================] - 0s 54us/sample - loss: 0.0930 - accuracy: 0.0000e+00 - recall: 0.9775 - precision: 0.7384 - val_loss: 0.1013 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.7547\n",
      "Epoch 237/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.0922 - accuracy: 0.0000e+00 - recall: 0.9836 - precision: 0.7373 - val_loss: 0.1003 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.7576\n",
      "Epoch 238/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.0914 - accuracy: 0.0000e+00 - recall: 0.9836 - precision: 0.7373 - val_loss: 0.0994 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.7634\n",
      "Epoch 239/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.0905 - accuracy: 0.0000e+00 - recall: 0.9836 - precision: 0.7419 - val_loss: 0.0985 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.7595\n",
      "Epoch 240/500\n",
      "488/488 [==============================] - 0s 64us/sample - loss: 0.0896 - accuracy: 0.0000e+00 - recall: 0.9836 - precision: 0.7419 - val_loss: 0.0974 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.7643\n",
      "Epoch 241/500\n",
      "488/488 [==============================] - 0s 65us/sample - loss: 0.0886 - accuracy: 0.0000e+00 - recall: 0.9857 - precision: 0.7377 - val_loss: 0.0962 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.7614\n",
      "Epoch 242/500\n",
      "488/488 [==============================] - 0s 73us/sample - loss: 0.0875 - accuracy: 0.0000e+00 - recall: 0.9877 - precision: 0.7508 - val_loss: 0.0951 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.7821\n",
      "Epoch 243/500\n",
      "488/488 [==============================] - 0s 64us/sample - loss: 0.0865 - accuracy: 0.0000e+00 - recall: 0.9857 - precision: 0.7758 - val_loss: 0.0940 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.8138\n",
      "Epoch 244/500\n",
      "488/488 [==============================] - 0s 68us/sample - loss: 0.0852 - accuracy: 0.0000e+00 - recall: 0.9877 - precision: 0.8183 - val_loss: 0.0926 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.8481\n",
      "Epoch 245/500\n",
      "488/488 [==============================] - 0s 63us/sample - loss: 0.0840 - accuracy: 0.0000e+00 - recall: 0.9898 - precision: 0.8444 - val_loss: 0.0911 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.8701\n",
      "Epoch 246/500\n",
      "488/488 [==============================] - 0s 55us/sample - loss: 0.0828 - accuracy: 0.0000e+00 - recall: 0.9898 - precision: 0.8687 - val_loss: 0.0898 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.8855\n",
      "Epoch 247/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.0813 - accuracy: 0.0000e+00 - recall: 0.9877 - precision: 0.8877 - val_loss: 0.0886 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.8973\n",
      "Epoch 248/500\n",
      "488/488 [==============================] - 0s 61us/sample - loss: 0.0799 - accuracy: 0.0000e+00 - recall: 0.9836 - precision: 0.8989 - val_loss: 0.0871 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9013\n",
      "Epoch 249/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.0785 - accuracy: 0.0000e+00 - recall: 0.9857 - precision: 0.9110 - val_loss: 0.0852 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9050\n",
      "Epoch 250/500\n",
      "488/488 [==============================] - 0s 61us/sample - loss: 0.0769 - accuracy: 0.0000e+00 - recall: 0.9898 - precision: 0.9218 - val_loss: 0.0837 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9132\n",
      "Epoch 251/500\n",
      "488/488 [==============================] - 0s 76us/sample - loss: 0.0754 - accuracy: 0.0000e+00 - recall: 0.9877 - precision: 0.9305 - val_loss: 0.0822 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9213\n",
      "Epoch 252/500\n",
      "488/488 [==============================] - 0s 66us/sample - loss: 0.0739 - accuracy: 0.0000e+00 - recall: 0.9816 - precision: 0.9374 - val_loss: 0.0807 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9256\n",
      "Epoch 253/500\n",
      "488/488 [==============================] - 0s 53us/sample - loss: 0.0721 - accuracy: 0.0000e+00 - recall: 0.9857 - precision: 0.9469 - val_loss: 0.0791 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9302\n",
      "Epoch 254/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.0706 - accuracy: 0.0000e+00 - recall: 0.9836 - precision: 0.9562 - val_loss: 0.0775 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9346\n",
      "Epoch 255/500\n",
      "488/488 [==============================] - 0s 64us/sample - loss: 0.0689 - accuracy: 0.0000e+00 - recall: 0.9877 - precision: 0.9621 - val_loss: 0.0760 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9296\n",
      "Epoch 256/500\n",
      "488/488 [==============================] - 0s 66us/sample - loss: 0.0671 - accuracy: 0.0000e+00 - recall: 0.9836 - precision: 0.9524 - val_loss: 0.0748 - val_accuracy: 0.0000e+00 - val_recall: 0.9381 - val_precision: 0.9292\n",
      "Epoch 257/500\n",
      "488/488 [==============================] - 0s 64us/sample - loss: 0.0654 - accuracy: 0.0000e+00 - recall: 0.9775 - precision: 0.9521 - val_loss: 0.0735 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9252\n",
      "Epoch 258/500\n",
      "488/488 [==============================] - 0s 67us/sample - loss: 0.0638 - accuracy: 0.0000e+00 - recall: 0.9816 - precision: 0.9677 - val_loss: 0.0720 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9209\n",
      "Epoch 259/500\n",
      "488/488 [==============================] - 0s 57us/sample - loss: 0.0622 - accuracy: 0.0000e+00 - recall: 0.9877 - precision: 0.9698 - val_loss: 0.0703 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9209\n",
      "Epoch 260/500\n",
      "488/488 [==============================] - 0s 63us/sample - loss: 0.0606 - accuracy: 0.0000e+00 - recall: 0.9857 - precision: 0.9737 - val_loss: 0.0691 - val_accuracy: 0.0000e+00 - val_recall: 0.9286 - val_precision: 0.9286\n",
      "Epoch 261/500\n",
      "488/488 [==============================] - 0s 67us/sample - loss: 0.0591 - accuracy: 0.0000e+00 - recall: 0.9795 - precision: 0.9657 - val_loss: 0.0676 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9252\n",
      "Epoch 262/500\n",
      "488/488 [==============================] - 0s 60us/sample - loss: 0.0576 - accuracy: 0.0000e+00 - recall: 0.9877 - precision: 0.9757 - val_loss: 0.0666 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9387\n",
      "Epoch 263/500\n",
      "488/488 [==============================] - 0s 53us/sample - loss: 0.0561 - accuracy: 0.0000e+00 - recall: 0.9877 - precision: 0.9757 - val_loss: 0.0654 - val_accuracy: 0.0000e+00 - val_recall: 0.9381 - val_precision: 0.9249\n",
      "Epoch 264/500\n",
      "488/488 [==============================] - 0s 50us/sample - loss: 0.0547 - accuracy: 0.0000e+00 - recall: 0.9795 - precision: 0.9676 - val_loss: 0.0648 - val_accuracy: 0.0000e+00 - val_recall: 0.9238 - val_precision: 0.9238\n",
      "Epoch 265/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.0534 - accuracy: 0.0000e+00 - recall: 0.9734 - precision: 0.9694 - val_loss: 0.0633 - val_accuracy: 0.0000e+00 - val_recall: 0.9381 - val_precision: 0.9292\n",
      "Epoch 266/500\n",
      "488/488 [==============================] - 0s 61us/sample - loss: 0.0517 - accuracy: 0.0000e+00 - recall: 0.9836 - precision: 0.9776 - val_loss: 0.0620 - val_accuracy: 0.0000e+00 - val_recall: 0.9381 - val_precision: 0.9292\n",
      "Epoch 267/500\n",
      "488/488 [==============================] - 0s 67us/sample - loss: 0.0503 - accuracy: 0.0000e+00 - recall: 0.9898 - precision: 0.9797 - val_loss: 0.0609 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9343\n",
      "Epoch 268/500\n",
      "488/488 [==============================] - 0s 85us/sample - loss: 0.0492 - accuracy: 0.0000e+00 - recall: 0.9877 - precision: 0.9817 - val_loss: 0.0598 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9384\n",
      "Epoch 269/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/488 [==============================] - 0s 57us/sample - loss: 0.0479 - accuracy: 0.0000e+00 - recall: 0.9877 - precision: 0.9837 - val_loss: 0.0588 - val_accuracy: 0.0000e+00 - val_recall: 0.9381 - val_precision: 0.9249\n",
      "Epoch 270/500\n",
      "488/488 [==============================] - 0s 66us/sample - loss: 0.0467 - accuracy: 0.0000e+00 - recall: 0.9898 - precision: 0.9797 - val_loss: 0.0579 - val_accuracy: 0.0000e+00 - val_recall: 0.9381 - val_precision: 0.9292\n",
      "Epoch 271/500\n",
      "488/488 [==============================] - 0s 67us/sample - loss: 0.0454 - accuracy: 0.0000e+00 - recall: 0.9898 - precision: 0.9837 - val_loss: 0.0570 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9343\n",
      "Epoch 272/500\n",
      "488/488 [==============================] - 0s 68us/sample - loss: 0.0443 - accuracy: 0.0000e+00 - recall: 0.9918 - precision: 0.9837 - val_loss: 0.0562 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9299\n",
      "Epoch 273/500\n",
      "488/488 [==============================] - 0s 56us/sample - loss: 0.0430 - accuracy: 0.0000e+00 - recall: 0.9918 - precision: 0.9878 - val_loss: 0.0556 - val_accuracy: 0.0000e+00 - val_recall: 0.9333 - val_precision: 0.9289\n",
      "Epoch 274/500\n",
      "488/488 [==============================] - 0s 55us/sample - loss: 0.0421 - accuracy: 0.0000e+00 - recall: 0.9877 - precision: 0.9797 - val_loss: 0.0552 - val_accuracy: 0.0000e+00 - val_recall: 0.9333 - val_precision: 0.9289\n",
      "Epoch 275/500\n",
      "488/488 [==============================] - 0s 55us/sample - loss: 0.0412 - accuracy: 0.0000e+00 - recall: 0.9877 - precision: 0.9817 - val_loss: 0.0544 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9296\n",
      "Epoch 276/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.0399 - accuracy: 0.0000e+00 - recall: 0.9898 - precision: 0.9877 - val_loss: 0.0533 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9340\n",
      "Epoch 277/500\n",
      "488/488 [==============================] - 0s 63us/sample - loss: 0.0390 - accuracy: 0.0000e+00 - recall: 0.9877 - precision: 0.9857 - val_loss: 0.0523 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9429\n",
      "Epoch 278/500\n",
      "488/488 [==============================] - 0s 64us/sample - loss: 0.0380 - accuracy: 0.0000e+00 - recall: 0.9918 - precision: 0.9837 - val_loss: 0.0515 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9384\n",
      "Epoch 279/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.0371 - accuracy: 0.0000e+00 - recall: 0.9918 - precision: 0.9837 - val_loss: 0.0508 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9429\n",
      "Epoch 280/500\n",
      "488/488 [==============================] - 0s 61us/sample - loss: 0.0361 - accuracy: 0.0000e+00 - recall: 0.9898 - precision: 0.9877 - val_loss: 0.0503 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9429\n",
      "Epoch 281/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.0352 - accuracy: 0.0000e+00 - recall: 0.9939 - precision: 0.9838 - val_loss: 0.0498 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9384\n",
      "Epoch 282/500\n",
      "488/488 [==============================] - 0s 60us/sample - loss: 0.0345 - accuracy: 0.0000e+00 - recall: 0.9918 - precision: 0.9857 - val_loss: 0.0490 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9429\n",
      "Epoch 283/500\n",
      "488/488 [==============================] - 0s 55us/sample - loss: 0.0338 - accuracy: 0.0000e+00 - recall: 0.9918 - precision: 0.9857 - val_loss: 0.0483 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9429\n",
      "Epoch 284/500\n",
      "488/488 [==============================] - 0s 60us/sample - loss: 0.0330 - accuracy: 0.0000e+00 - recall: 0.9918 - precision: 0.9898 - val_loss: 0.0478 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 285/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.0325 - accuracy: 0.0000e+00 - recall: 0.9857 - precision: 0.9836 - val_loss: 0.0470 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9340\n",
      "Epoch 286/500\n",
      "488/488 [==============================] - 0s 66us/sample - loss: 0.0314 - accuracy: 0.0000e+00 - recall: 0.9918 - precision: 0.9918 - val_loss: 0.0466 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 287/500\n",
      "488/488 [==============================] - 0s 57us/sample - loss: 0.0309 - accuracy: 0.0000e+00 - recall: 0.9939 - precision: 0.9878 - val_loss: 0.0463 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9384\n",
      "Epoch 288/500\n",
      "488/488 [==============================] - 0s 68us/sample - loss: 0.0299 - accuracy: 0.0000e+00 - recall: 0.9918 - precision: 0.9878 - val_loss: 0.0465 - val_accuracy: 0.0000e+00 - val_recall: 0.9381 - val_precision: 0.9381\n",
      "Epoch 289/500\n",
      "488/488 [==============================] - 0s 54us/sample - loss: 0.0297 - accuracy: 0.0000e+00 - recall: 0.9857 - precision: 0.9857 - val_loss: 0.0452 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9384\n",
      "Epoch 290/500\n",
      "488/488 [==============================] - 0s 65us/sample - loss: 0.0287 - accuracy: 0.0000e+00 - recall: 0.9939 - precision: 0.9898 - val_loss: 0.0446 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9429\n",
      "Epoch 291/500\n",
      "488/488 [==============================] - 0s 65us/sample - loss: 0.0281 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9918 - val_loss: 0.0442 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9384\n",
      "Epoch 292/500\n",
      "488/488 [==============================] - 0s 69us/sample - loss: 0.0273 - accuracy: 0.0000e+00 - recall: 0.9939 - precision: 0.9918 - val_loss: 0.0439 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9384\n",
      "Epoch 293/500\n",
      "488/488 [==============================] - 0s 55us/sample - loss: 0.0269 - accuracy: 0.0000e+00 - recall: 0.9918 - precision: 0.9918 - val_loss: 0.0438 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9387\n",
      "Epoch 294/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.0261 - accuracy: 0.0000e+00 - recall: 0.9939 - precision: 0.9939 - val_loss: 0.0439 - val_accuracy: 0.0000e+00 - val_recall: 0.9381 - val_precision: 0.9381\n",
      "Epoch 295/500\n",
      "488/488 [==============================] - 0s 63us/sample - loss: 0.0259 - accuracy: 0.0000e+00 - recall: 0.9898 - precision: 0.9877 - val_loss: 0.0431 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9340\n",
      "Epoch 296/500\n",
      "488/488 [==============================] - 0s 70us/sample - loss: 0.0251 - accuracy: 0.0000e+00 - recall: 0.9939 - precision: 0.9918 - val_loss: 0.0427 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9479\n",
      "Epoch 297/500\n",
      "488/488 [==============================] - 0s 61us/sample - loss: 0.0252 - accuracy: 0.0000e+00 - recall: 0.9939 - precision: 0.9939 - val_loss: 0.0426 - val_accuracy: 0.0000e+00 - val_recall: 0.9381 - val_precision: 0.9336\n",
      "Epoch 298/500\n",
      "488/488 [==============================] - 0s 55us/sample - loss: 0.0245 - accuracy: 0.0000e+00 - recall: 0.9939 - precision: 0.9918 - val_loss: 0.0429 - val_accuracy: 0.0000e+00 - val_recall: 0.9381 - val_precision: 0.9381\n",
      "Epoch 299/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.0238 - accuracy: 0.0000e+00 - recall: 0.9939 - precision: 0.9898 - val_loss: 0.0418 - val_accuracy: 0.0000e+00 - val_recall: 0.9381 - val_precision: 0.9381\n",
      "Epoch 300/500\n",
      "488/488 [==============================] - 0s 66us/sample - loss: 0.0233 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9918 - val_loss: 0.0411 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 301/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.0228 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9918 - val_loss: 0.0405 - val_accuracy: 0.0000e+00 - val_recall: 0.9619 - val_precision: 0.9528\n",
      "Epoch 302/500\n",
      "488/488 [==============================] - 0s 67us/sample - loss: 0.0223 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9918 - val_loss: 0.0403 - val_accuracy: 0.0000e+00 - val_recall: 0.9381 - val_precision: 0.9381\n",
      "Epoch 303/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/488 [==============================] - 0s 63us/sample - loss: 0.0223 - accuracy: 0.0000e+00 - recall: 0.9918 - precision: 0.9918 - val_loss: 0.0401 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9429\n",
      "Epoch 304/500\n",
      "488/488 [==============================] - 0s 78us/sample - loss: 0.0220 - accuracy: 0.0000e+00 - recall: 0.9939 - precision: 0.9918 - val_loss: 0.0399 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 305/500\n",
      "488/488 [==============================] - 0s 56us/sample - loss: 0.0213 - accuracy: 0.0000e+00 - recall: 0.9918 - precision: 0.9918 - val_loss: 0.0401 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9340\n",
      "Epoch 306/500\n",
      "488/488 [==============================] - 0s 53us/sample - loss: 0.0208 - accuracy: 0.0000e+00 - recall: 0.9939 - precision: 0.9939 - val_loss: 0.0398 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9429\n",
      "Epoch 307/500\n",
      "488/488 [==============================] - 0s 60us/sample - loss: 0.0204 - accuracy: 0.0000e+00 - recall: 0.9939 - precision: 0.9939 - val_loss: 0.0393 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 308/500\n",
      "488/488 [==============================] - 0s 60us/sample - loss: 0.0200 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9959 - val_loss: 0.0393 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9429\n",
      "Epoch 309/500\n",
      "488/488 [==============================] - 0s 65us/sample - loss: 0.0195 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9959 - val_loss: 0.0391 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 310/500\n",
      "488/488 [==============================] - 0s 64us/sample - loss: 0.0192 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9959 - val_loss: 0.0388 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 311/500\n",
      "488/488 [==============================] - 0s 63us/sample - loss: 0.0189 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9959 - val_loss: 0.0390 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9429\n",
      "Epoch 312/500\n",
      "488/488 [==============================] - 0s 65us/sample - loss: 0.0185 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9959 - val_loss: 0.0390 - val_accuracy: 0.0000e+00 - val_recall: 0.9381 - val_precision: 0.9381\n",
      "Epoch 313/500\n",
      "488/488 [==============================] - 0s 54us/sample - loss: 0.0183 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9959 - val_loss: 0.0390 - val_accuracy: 0.0000e+00 - val_recall: 0.9381 - val_precision: 0.9381\n",
      "Epoch 314/500\n",
      "488/488 [==============================] - 0s 67us/sample - loss: 0.0179 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9959 - val_loss: 0.0386 - val_accuracy: 0.0000e+00 - val_recall: 0.9381 - val_precision: 0.9381\n",
      "Epoch 315/500\n",
      "488/488 [==============================] - 0s 64us/sample - loss: 0.0176 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9959 - val_loss: 0.0380 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9429\n",
      "Epoch 316/500\n",
      "488/488 [==============================] - 0s 66us/sample - loss: 0.0172 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9959 - val_loss: 0.0373 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 317/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.0170 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9959 - val_loss: 0.0369 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 318/500\n",
      "488/488 [==============================] - 0s 52us/sample - loss: 0.0167 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9959 - val_loss: 0.0371 - val_accuracy: 0.0000e+00 - val_recall: 0.9381 - val_precision: 0.9336\n",
      "Epoch 319/500\n",
      "488/488 [==============================] - 0s 76us/sample - loss: 0.0165 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9939 - val_loss: 0.0363 - val_accuracy: 0.0000e+00 - val_recall: 0.9619 - val_precision: 0.9528\n",
      "Epoch 320/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.0162 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9959 - val_loss: 0.0357 - val_accuracy: 0.0000e+00 - val_recall: 0.9619 - val_precision: 0.9619\n",
      "Epoch 321/500\n",
      "488/488 [==============================] - 0s 63us/sample - loss: 0.0164 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9959 - val_loss: 0.0356 - val_accuracy: 0.0000e+00 - val_recall: 0.9619 - val_precision: 0.9619\n",
      "Epoch 322/500\n",
      "488/488 [==============================] - 0s 60us/sample - loss: 0.0156 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9959 - val_loss: 0.0369 - val_accuracy: 0.0000e+00 - val_recall: 0.9333 - val_precision: 0.9333\n",
      "Epoch 323/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.0159 - accuracy: 0.0000e+00 - recall: 0.9939 - precision: 0.9939 - val_loss: 0.0361 - val_accuracy: 0.0000e+00 - val_recall: 0.9381 - val_precision: 0.9381\n",
      "Epoch 324/500\n",
      "488/488 [==============================] - 0s 53us/sample - loss: 0.0155 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9959 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 325/500\n",
      "488/488 [==============================] - 0s 51us/sample - loss: 0.0155 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9939 - val_loss: 0.0351 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 326/500\n",
      "488/488 [==============================] - 0s 55us/sample - loss: 0.0151 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9959 - val_loss: 0.0362 - val_accuracy: 0.0000e+00 - val_recall: 0.9381 - val_precision: 0.9381\n",
      "Epoch 327/500\n",
      "488/488 [==============================] - 0s 53us/sample - loss: 0.0150 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9918 - val_loss: 0.0344 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 328/500\n",
      "488/488 [==============================] - 0s 61us/sample - loss: 0.0143 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9980 - val_loss: 0.0343 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 329/500\n",
      "488/488 [==============================] - 0s 56us/sample - loss: 0.0142 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9959 - val_loss: 0.0347 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9429\n",
      "Epoch 330/500\n",
      "488/488 [==============================] - 0s 56us/sample - loss: 0.0139 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9959 - val_loss: 0.0353 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9429\n",
      "Epoch 331/500\n",
      "488/488 [==============================] - 0s 61us/sample - loss: 0.0138 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9959 - val_loss: 0.0344 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 332/500\n",
      "488/488 [==============================] - 0s 61us/sample - loss: 0.0135 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9959 - val_loss: 0.0341 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 333/500\n",
      "488/488 [==============================] - 0s 63us/sample - loss: 0.0133 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9959 - val_loss: 0.0342 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 334/500\n",
      "488/488 [==============================] - 0s 70us/sample - loss: 0.0130 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9959 - val_loss: 0.0338 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 335/500\n",
      "488/488 [==============================] - 0s 51us/sample - loss: 0.0129 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9959 - val_loss: 0.0333 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 336/500\n",
      "488/488 [==============================] - 0s 57us/sample - loss: 0.0126 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9959 - val_loss: 0.0333 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 337/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/488 [==============================] - 0s 60us/sample - loss: 0.0125 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9959 - val_loss: 0.0332 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 338/500\n",
      "488/488 [==============================] - 0s 63us/sample - loss: 0.0123 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9959 - val_loss: 0.0333 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 339/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.0121 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9959 - val_loss: 0.0330 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 340/500\n",
      "488/488 [==============================] - 0s 60us/sample - loss: 0.0121 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9959 - val_loss: 0.0331 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 341/500\n",
      "488/488 [==============================] - 0s 60us/sample - loss: 0.0120 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9980 - val_loss: 0.0338 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 342/500\n",
      "488/488 [==============================] - 0s 63us/sample - loss: 0.0117 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9980 - val_loss: 0.0328 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 343/500\n",
      "488/488 [==============================] - 0s 65us/sample - loss: 0.0116 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9980 - val_loss: 0.0329 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 344/500\n",
      "488/488 [==============================] - 0s 55us/sample - loss: 0.0113 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9980 - val_loss: 0.0336 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 345/500\n",
      "488/488 [==============================] - 0s 64us/sample - loss: 0.0114 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9980 - val_loss: 0.0326 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 346/500\n",
      "488/488 [==============================] - 0s 56us/sample - loss: 0.0109 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9980 - val_loss: 0.0321 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9429\n",
      "Epoch 347/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.0115 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9980 - val_loss: 0.0323 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 348/500\n",
      "488/488 [==============================] - 0s 66us/sample - loss: 0.0109 - accuracy: 0.0000e+00 - recall: 0.9959 - precision: 0.9959 - val_loss: 0.0336 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 349/500\n",
      "488/488 [==============================] - 0s 49us/sample - loss: 0.0110 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9980 - val_loss: 0.0328 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 350/500\n",
      "488/488 [==============================] - 0s 55us/sample - loss: 0.0105 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9980 - val_loss: 0.0325 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 351/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.0103 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 0.9980 - val_loss: 0.0318 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 352/500\n",
      "488/488 [==============================] - 0s 61us/sample - loss: 0.0103 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9980 - val_loss: 0.0316 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9526\n",
      "Epoch 353/500\n",
      "488/488 [==============================] - 0s 60us/sample - loss: 0.0102 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9959 - val_loss: 0.0321 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 354/500\n",
      "488/488 [==============================] - 0s 57us/sample - loss: 0.0100 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9980 - val_loss: 0.0311 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 355/500\n",
      "488/488 [==============================] - 0s 60us/sample - loss: 0.0099 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9980 - val_loss: 0.0310 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 356/500\n",
      "488/488 [==============================] - 0s 73us/sample - loss: 0.0099 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9980 - val_loss: 0.0318 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 357/500\n",
      "488/488 [==============================] - 0s 96us/sample - loss: 0.0098 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9980 - val_loss: 0.0327 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9431\n",
      "Epoch 358/500\n",
      "488/488 [==============================] - 0s 53us/sample - loss: 0.0095 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9980 - val_loss: 0.0313 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 359/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.0093 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0309 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 360/500\n",
      "488/488 [==============================] - 0s 57us/sample - loss: 0.0096 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9980 - val_loss: 0.0312 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 361/500\n",
      "488/488 [==============================] - 0s 55us/sample - loss: 0.0092 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0322 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 362/500\n",
      "488/488 [==============================] - 0s 51us/sample - loss: 0.0090 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9980 - val_loss: 0.0315 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 363/500\n",
      "488/488 [==============================] - 0s 54us/sample - loss: 0.0089 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0310 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 364/500\n",
      "488/488 [==============================] - 0s 56us/sample - loss: 0.0088 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0308 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 365/500\n",
      "488/488 [==============================] - 0s 55us/sample - loss: 0.0087 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 366/500\n",
      "488/488 [==============================] - 0s 53us/sample - loss: 0.0086 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0315 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 367/500\n",
      "488/488 [==============================] - 0s 46us/sample - loss: 0.0086 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0311 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 368/500\n",
      "488/488 [==============================] - 0s 54us/sample - loss: 0.0084 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 369/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.0082 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0311 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 370/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.0082 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9980 - val_loss: 0.0307 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 371/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/488 [==============================] - 0s 60us/sample - loss: 0.0080 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0302 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 372/500\n",
      "488/488 [==============================] - 0s 60us/sample - loss: 0.0085 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9980 - val_loss: 0.0306 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 373/500\n",
      "488/488 [==============================] - 0s 57us/sample - loss: 0.0081 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.0000e+00 - val_recall: 0.9429 - val_precision: 0.9429\n",
      "Epoch 374/500\n",
      "488/488 [==============================] - 0s 49us/sample - loss: 0.0081 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9980 - val_loss: 0.0310 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 375/500\n",
      "488/488 [==============================] - 0s 48us/sample - loss: 0.0078 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0306 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 376/500\n",
      "488/488 [==============================] - 0s 57us/sample - loss: 0.0077 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 377/500\n",
      "488/488 [==============================] - 0s 55us/sample - loss: 0.0076 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0305 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 378/500\n",
      "488/488 [==============================] - 0s 54us/sample - loss: 0.0074 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.0000e+00 - val_recall: 0.9619 - val_precision: 0.9573\n",
      "Epoch 379/500\n",
      "488/488 [==============================] - 0s 52us/sample - loss: 0.0074 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.0000e+00 - val_recall: 0.9619 - val_precision: 0.9619\n",
      "Epoch 380/500\n",
      "488/488 [==============================] - 0s 51us/sample - loss: 0.0072 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0307 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 381/500\n",
      "488/488 [==============================] - 0s 56us/sample - loss: 0.0073 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0304 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 382/500\n",
      "488/488 [==============================] - 0s 52us/sample - loss: 0.0073 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0302 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9526\n",
      "Epoch 383/500\n",
      "488/488 [==============================] - 0s 57us/sample - loss: 0.0070 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 384/500\n",
      "488/488 [==============================] - 0s 53us/sample - loss: 0.0071 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0312 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 385/500\n",
      "488/488 [==============================] - 0s 51us/sample - loss: 0.0069 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 386/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.0069 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0293 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 387/500\n",
      "488/488 [==============================] - 0s 57us/sample - loss: 0.0069 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 388/500\n",
      "488/488 [==============================] - 0s 57us/sample - loss: 0.0069 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0307 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9526\n",
      "Epoch 389/500\n",
      "488/488 [==============================] - 0s 55us/sample - loss: 0.0068 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 390/500\n",
      "488/488 [==============================] - 0s 57us/sample - loss: 0.0068 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 391/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.0064 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0306 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 392/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.0067 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0308 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 393/500\n",
      "488/488 [==============================] - 0s 65us/sample - loss: 0.0065 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 394/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.0065 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 395/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.0066 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 396/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.0064 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9980 - val_loss: 0.0319 - val_accuracy: 0.0000e+00 - val_recall: 0.9381 - val_precision: 0.9336\n",
      "Epoch 397/500\n",
      "488/488 [==============================] - 0s 67us/sample - loss: 0.0066 - accuracy: 0.0000e+00 - recall: 0.9980 - precision: 0.9980 - val_loss: 0.0299 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 398/500\n",
      "488/488 [==============================] - 0s 61us/sample - loss: 0.0061 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9431\n",
      "Epoch 399/500\n",
      "488/488 [==============================] - 0s 57us/sample - loss: 0.0067 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0299 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9526\n",
      "Epoch 400/500\n",
      "488/488 [==============================] - 0s 61us/sample - loss: 0.0061 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0311 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 401/500\n",
      "488/488 [==============================] - 0s 61us/sample - loss: 0.0061 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0292 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 402/500\n",
      "488/488 [==============================] - 0s 66us/sample - loss: 0.0063 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0289 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 403/500\n",
      "488/488 [==============================] - 0s 60us/sample - loss: 0.0060 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0300 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 404/500\n",
      "488/488 [==============================] - 0s 63us/sample - loss: 0.0060 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0309 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 405/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/488 [==============================] - 0s 55us/sample - loss: 0.0057 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0298 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 406/500\n",
      "488/488 [==============================] - 0s 66us/sample - loss: 0.0056 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 407/500\n",
      "488/488 [==============================] - 0s 63us/sample - loss: 0.0059 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0301 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 408/500\n",
      "488/488 [==============================] - 0s 54us/sample - loss: 0.0054 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0306 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 409/500\n",
      "488/488 [==============================] - 0s 57us/sample - loss: 0.0055 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 410/500\n",
      "488/488 [==============================] - 0s 60us/sample - loss: 0.0054 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0290 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 411/500\n",
      "488/488 [==============================] - 0s 55us/sample - loss: 0.0053 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0293 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 412/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.0052 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0298 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 413/500\n",
      "488/488 [==============================] - 0s 53us/sample - loss: 0.0052 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0300 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 414/500\n",
      "488/488 [==============================] - 0s 49us/sample - loss: 0.0052 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 415/500\n",
      "488/488 [==============================] - 0s 52us/sample - loss: 0.0050 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0290 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 416/500\n",
      "488/488 [==============================] - 0s 53us/sample - loss: 0.0051 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0290 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 417/500\n",
      "488/488 [==============================] - 0s 51us/sample - loss: 0.0050 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0293 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 418/500\n",
      "488/488 [==============================] - 0s 69us/sample - loss: 0.0050 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0293 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 419/500\n",
      "488/488 [==============================] - 0s 47us/sample - loss: 0.0049 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 420/500\n",
      "488/488 [==============================] - 0s 51us/sample - loss: 0.0048 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0289 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 421/500\n",
      "488/488 [==============================] - 0s 51us/sample - loss: 0.0049 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0289 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 422/500\n",
      "488/488 [==============================] - 0s 53us/sample - loss: 0.0048 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 423/500\n",
      "488/488 [==============================] - 0s 54us/sample - loss: 0.0048 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 424/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.0048 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 425/500\n",
      "488/488 [==============================] - 0s 57us/sample - loss: 0.0047 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 426/500\n",
      "488/488 [==============================] - 0s 56us/sample - loss: 0.0046 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0292 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 427/500\n",
      "488/488 [==============================] - 0s 55us/sample - loss: 0.0046 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0298 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 428/500\n",
      "488/488 [==============================] - 0s 57us/sample - loss: 0.0046 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 429/500\n",
      "488/488 [==============================] - 0s 56us/sample - loss: 0.0045 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 430/500\n",
      "488/488 [==============================] - 0s 54us/sample - loss: 0.0044 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 431/500\n",
      "488/488 [==============================] - 0s 51us/sample - loss: 0.0044 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 432/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.0043 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0293 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 433/500\n",
      "488/488 [==============================] - 0s 56us/sample - loss: 0.0043 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 434/500\n",
      "488/488 [==============================] - 0s 53us/sample - loss: 0.0043 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 435/500\n",
      "488/488 [==============================] - 0s 64us/sample - loss: 0.0043 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0290 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 436/500\n",
      "488/488 [==============================] - 0s 50us/sample - loss: 0.0042 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0293 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 437/500\n",
      "488/488 [==============================] - 0s 50us/sample - loss: 0.0042 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 438/500\n",
      "488/488 [==============================] - 0s 55us/sample - loss: 0.0042 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 439/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/488 [==============================] - 0s 59us/sample - loss: 0.0041 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0292 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 440/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.0041 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0293 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 441/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.0040 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0293 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 442/500\n",
      "488/488 [==============================] - 0s 61us/sample - loss: 0.0040 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0288 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9526\n",
      "Epoch 443/500\n",
      "488/488 [==============================] - 0s 63us/sample - loss: 0.0040 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0287 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 444/500\n",
      "488/488 [==============================] - 0s 60us/sample - loss: 0.0039 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0289 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 445/500\n",
      "488/488 [==============================] - 0s 55us/sample - loss: 0.0039 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 446/500\n",
      "488/488 [==============================] - 0s 72us/sample - loss: 0.0039 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 447/500\n",
      "488/488 [==============================] - 0s 46us/sample - loss: 0.0039 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0290 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 448/500\n",
      "488/488 [==============================] - 0s 60us/sample - loss: 0.0039 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 449/500\n",
      "488/488 [==============================] - 0s 57us/sample - loss: 0.0038 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0292 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 450/500\n",
      "488/488 [==============================] - 0s 63us/sample - loss: 0.0038 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0288 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 451/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.0039 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0284 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 452/500\n",
      "488/488 [==============================] - 0s 51us/sample - loss: 0.0038 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0286 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 453/500\n",
      "488/488 [==============================] - 0s 54us/sample - loss: 0.0037 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0287 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 454/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.0036 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0290 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 455/500\n",
      "488/488 [==============================] - 0s 72us/sample - loss: 0.0036 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0289 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 456/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.0036 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0289 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9526\n",
      "Epoch 457/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.0035 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0290 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 458/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.0035 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0292 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9479\n",
      "Epoch 459/500\n",
      "488/488 [==============================] - 0s 55us/sample - loss: 0.0035 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 460/500\n",
      "488/488 [==============================] - 0s 65us/sample - loss: 0.0035 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 461/500\n",
      "488/488 [==============================] - 0s 56us/sample - loss: 0.0034 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0293 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 462/500\n",
      "488/488 [==============================] - 0s 66us/sample - loss: 0.0034 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 463/500\n",
      "488/488 [==============================] - 0s 65us/sample - loss: 0.0034 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 464/500\n",
      "488/488 [==============================] - 0s 60us/sample - loss: 0.0033 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0290 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 465/500\n",
      "488/488 [==============================] - 0s 56us/sample - loss: 0.0034 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0290 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 466/500\n",
      "488/488 [==============================] - 0s 60us/sample - loss: 0.0033 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 467/500\n",
      "488/488 [==============================] - 0s 61us/sample - loss: 0.0033 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 468/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.0033 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 469/500\n",
      "488/488 [==============================] - 0s 64us/sample - loss: 0.0033 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 470/500\n",
      "488/488 [==============================] - 0s 63us/sample - loss: 0.0032 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0301 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 471/500\n",
      "488/488 [==============================] - 0s 54us/sample - loss: 0.0032 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 472/500\n",
      "488/488 [==============================] - 0s 54us/sample - loss: 0.0032 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0292 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 473/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/488 [==============================] - 0s 51us/sample - loss: 0.0032 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0292 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 474/500\n",
      "488/488 [==============================] - 0s 48us/sample - loss: 0.0031 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 475/500\n",
      "488/488 [==============================] - 0s 50us/sample - loss: 0.0031 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 476/500\n",
      "488/488 [==============================] - 0s 50us/sample - loss: 0.0031 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0293 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 477/500\n",
      "488/488 [==============================] - 0s 56us/sample - loss: 0.0031 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 478/500\n",
      "488/488 [==============================] - 0s 57us/sample - loss: 0.0030 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0293 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 479/500\n",
      "488/488 [==============================] - 0s 53us/sample - loss: 0.0030 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0293 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 480/500\n",
      "488/488 [==============================] - 0s 49us/sample - loss: 0.0030 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0290 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 481/500\n",
      "488/488 [==============================] - 0s 55us/sample - loss: 0.0029 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0289 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 482/500\n",
      "488/488 [==============================] - 0s 56us/sample - loss: 0.0029 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0289 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 483/500\n",
      "488/488 [==============================] - 0s 52us/sample - loss: 0.0029 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0290 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 484/500\n",
      "488/488 [==============================] - 0s 78us/sample - loss: 0.0029 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 485/500\n",
      "488/488 [==============================] - 0s 60us/sample - loss: 0.0029 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 486/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.0028 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 487/500\n",
      "488/488 [==============================] - 0s 51us/sample - loss: 0.0028 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.0000e+00 - val_recall: 0.9571 - val_precision: 0.9571\n",
      "Epoch 488/500\n",
      "488/488 [==============================] - 0s 54us/sample - loss: 0.0028 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0293 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 489/500\n",
      "488/488 [==============================] - 0s 59us/sample - loss: 0.0028 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9479\n",
      "Epoch 490/500\n",
      "488/488 [==============================] - 0s 56us/sample - loss: 0.0028 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 491/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.0027 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0293 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 492/500\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.0027 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0293 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 493/500\n",
      "488/488 [==============================] - 0s 72us/sample - loss: 0.0027 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0293 - val_accuracy: 0.0000e+00 - val_recall: 0.9524 - val_precision: 0.9524\n",
      "Epoch 494/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.0027 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 495/500\n",
      "488/488 [==============================] - 0s 65us/sample - loss: 0.0026 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0293 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 496/500\n",
      "488/488 [==============================] - 0s 56us/sample - loss: 0.0026 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 497/500\n",
      "488/488 [==============================] - 0s 62us/sample - loss: 0.0026 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 498/500\n",
      "488/488 [==============================] - 0s 66us/sample - loss: 0.0026 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 499/500\n",
      "488/488 [==============================] - 0s 57us/sample - loss: 0.0026 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0298 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n",
      "Epoch 500/500\n",
      "488/488 [==============================] - 0s 63us/sample - loss: 0.0026 - accuracy: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.0000e+00 - val_recall: 0.9476 - val_precision: 0.9476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc57c8ab150>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "ANN_model.fit(train_X, np.array(new_train_Y), validation_data=(test_X, np.array(new_test_Y)), epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[45,  0,  5],\n",
       "       [ 0, 72,  0],\n",
       "       [ 3,  3, 82]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "pred_Y = ANN_model.predict_classes(test_X);\n",
    "confusion_matrix(test_Y, pred_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "210/210 [==============================] - 0s 98us/sample - loss: 0.0297 - accuracy: 0.0000e+00 - recall: 0.9476 - precision: 0.9476\n",
      "accuracy: 0.03\n",
      "recall: 0.00\n",
      "precision: 0.95\n"
     ]
    }
   ],
   "source": [
    "# report evaluation metrics \n",
    "evaluated_metrics = ANN_model.evaluate(test_X, np.array(new_test_Y))\n",
    "for i in range(len(metrics)):\n",
    "    print(metrics_names[i] + \": %.2f\" % evaluated_metrics[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

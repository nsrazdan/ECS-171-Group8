{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing - ECS171 Project Group 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description**: Converts true/false entries to 1/0 and normalizes numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (18,19,23) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "path_nontrend = 'datasets/11.09 nontrending.csv'\n",
    "path_trend = 'datasets/11.09 trending.csv'\n",
    "df_nontrend = pd.read_csv(path_nontrend)\n",
    "df_trend = pd.read_csv(path_trend)\n",
    "df_nontrend.head()\n",
    "\n",
    "df_nontrend = df_nontrend.drop(['dimension'],axis=1)\n",
    "df_trend = df_trend.drop(['dimension'],axis=1)\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def handle_duplicates(dfn, dft):\n",
    "    \n",
    "#     trend_later_list = []\n",
    "#     drop_list = []\n",
    "    \n",
    "#     for row in dfn.index:\n",
    "#         if dfn['video_id'][row] in dft['video_id']:\n",
    "#             trend_later_list.append(dfn['video_id'][row])\n",
    "#             drop_list.append(row)\n",
    "    \n",
    "#     dft['trend_later'] = False\n",
    "#     for ids in trend_later_list:\n",
    "#         dft.iloc[dft[dft['video_id'] == ids].index.values]['trend_later'] = True\n",
    "#     dfn.drop(drop_list, axis = 0, inplace = True)\n",
    "#     dfn['trend_later'] = False\n",
    "    \n",
    "def excess_remove(dft, dfn):\n",
    "    excess = []\n",
    "    for col in dfn.columns:\n",
    "        if col not in dft.columns:\n",
    "            excess.append(col)\n",
    "    dfn.drop(excess, axis = 1, inplace = True)\n",
    "    \n",
    "def update_remove(df, kept_date):\n",
    "    prospects = []\n",
    "    remove = []\n",
    "    for cols in df.columns:\n",
    "        if \"timestamp\" in cols or \"likes\" in cols or \"dislikes\" in cols or \"comment\" in cols or \"view\" in cols:\n",
    "            prospects.append(cols)\n",
    "    for col2 in prospects:\n",
    "        if kept_date not in col2 and  \"Channel_viewCount\" not in col2 :\n",
    "            remove.append(col2)\n",
    "    return remove\n",
    "\n",
    "#convert quotations '\\\"'\n",
    "#function: remove_quote(column)\n",
    "#use on nontrend (definition, Channel_country) and trend (Channel_country)\n",
    "def remove_quote(col):\n",
    "    lst = []\n",
    "    for v in col:\n",
    "        if type(v) == str:\n",
    "            lst.append(v.replace('\"',''))\n",
    "        else:\n",
    "            lst.append(v)\n",
    "    return lst\n",
    "\n",
    "\n",
    "#sets 'tags' to number of tags\n",
    "#function: count_tags(dataframe)\n",
    "#use on nontrend and trend\n",
    "def count_tags(df):\n",
    "    lst=[]\n",
    "    for entry in df['tags']:\n",
    "        if entry == '[none]':\n",
    "            lst.append(0)\n",
    "        else:\n",
    "            num_tags = entry.count('|')\n",
    "            lst.append(num_tags)\n",
    "    df['tags'] = lst\n",
    "\n",
    "\n",
    "#Channel_country: 0 for INTL, 1 for USA\n",
    "#function: encode_country(dataframe)\n",
    "#use on nontrend and trend\n",
    "def encode_country(df):\n",
    "    lst = []\n",
    "    for entry in df['Channel_country']:\n",
    "        if entry == 'US':\n",
    "            lst.append(\"USA\")\n",
    "        elif entry == \"\":\n",
    "            lst.append(\"UNK\")\n",
    "        else:\n",
    "            lst.append(\"INTL\")\n",
    "    df['Channel_country'] = lst\n",
    "\n",
    "#remove Channel_hiddenSubscriberCount == True rows\n",
    "#function: clean_subcount(dataframe)\n",
    "#use on nontrend\n",
    "def clean_subcount(df):\n",
    "    lst = []\n",
    "    for i in df.index:\n",
    "        if df['Channel_hiddenSubscriberCount'][i] == True:\n",
    "            lst.append(i)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "#if a video is in both '11.09 nontrending' and '11.09 trending', drop it from nontrending (it was never nontrending.) If it shows up in one of the later trending video sets, add that information\n",
    "\n",
    "#pass trending dframe as dft, nontrending as dfn\n",
    "def handle_trending(dft,dfn):\n",
    "    path= './datasets'\n",
    "    trending = [f for f in listdir(path) if isfile(join(path, f)) and \" trending\" in f]\n",
    "\n",
    "    all_trending_ids = set()\n",
    "    for i in trending:\n",
    "        all_trending_ids.update(pd.read_csv(f\"{path}/{i}\")[\"video_id\"].to_list())\n",
    "\n",
    "    original_trending_ids = dft[\"video_id\"].to_list()\n",
    "\n",
    "    trended = set()\n",
    "    duplicate = set()\n",
    "    for i in dfn.index:\n",
    "        if dfn[\"video_id\"][i] in all_trending_ids:\n",
    "            trended.update([i])\n",
    "        if dfn[\"video_id\"][i] in original_trending_ids:\n",
    "            duplicate.update([i])\n",
    "    trended = trended.symmetric_difference(duplicate)\n",
    "\n",
    "    #drop videos which are duplicates of videos in the \"11.09 trending\" database\n",
    "    dfn.drop(duplicate, inplace=True)\n",
    "\n",
    "    #these videos were not originally trending, but started trending later. \n",
    "    dfn.insert(10,\"trended_later\",False)\n",
    "    dfn.loc[trended,\"trended_later\"]=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_trending(df_trend, df_nontrend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trend['trending?'] = True\n",
    "df_nontrend['trending?'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "excess_remove(df_trend, df_nontrend)\n",
    "frames = [df_trend, df_nontrend]\n",
    "# Link that teaches how to concatenate:\n",
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html\n",
    "df = pd.concat(frames, ignore_index=True, sort=False)\n",
    "#df.reset_index(drop=True)\n",
    "#df = df_trend\n",
    "df = df.drop(['Unnamed: 0','is_trending'], axis=1)\n",
    "#df.to_csv(\"~/CS/ECS-171-Group8/orig_DataProcessNotebook.csv\")\n",
    "#df.reset_index(drop=True)\n",
    "df.dropna(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['duration'] != type(str)]\n",
    "\n",
    "index = 0\n",
    "lst_drop = []\n",
    "for i in df['duration']:\n",
    "    if type(i) != str:\n",
    "        lst_drop.append(index)\n",
    "    index += 1\n",
    "df.drop(lst_drop, inplace = True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------\n",
    "# installation: pip3 install isodate\n",
    "import isodate\n",
    "duration_seconds = []\n",
    "\n",
    "for i in df['duration']:\n",
    "    dur = isodate.parse_duration(i.replace('\"','' ))\n",
    "    duration_seconds.append(dur.total_seconds())\n",
    "df['duration'] = duration_seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engagementRate(likes, comment, subscriber):\n",
    "    return (likes + comment)/subscriber\n",
    "\n",
    "#drop any na values from the dataset\n",
    "df = df.dropna()\n",
    "\n",
    "like_col = [col for col in df if col.startswith('likes') ]\n",
    "comment_col = [col for col in df if col.startswith('comment') ]\n",
    "subscriber_col = [col for col in df if col.startswith('Channel_subscriberCount') ]\n",
    "\n",
    "#feed the data to the formula and store the result in engagement rate\n",
    "df[\"engagement_rate\"] = engagementRate(df[like_col[len(like_col)-1]],df[comment_col[len(comment_col)-1]], df[subscriber_col[len(subscriber_col)-1]])\n",
    "\n",
    "#replace any infinite values with nan\n",
    "df[\"engagement_rate\"] = df[\"engagement_rate\"].replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.drop(update_remove(df, \"11_19\"), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "numeric_cols = ['duration', 'Channel_viewCount', 'Channel_subscriberCount', 'Channel_videoCount', 'view_count_update_11_19_14', 'likes_update_11_19_14', 'dislikes_update_11_19_14', 'comment_count_update_11_19_14',]\n",
    "new_df[numeric_cols] = StandardScaler().fit_transform(new_df[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plt.hist(new_df['Channel_country'])\n",
    "# plt.subplots(figsize=(71,71))\n",
    "# sns.countplot(new_df['Channel_country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'count'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c8286bf44247>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Channel_country'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_quote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Channel_country'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcount_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mencode_country\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-9b09cec12c83>\u001b[0m in \u001b[0;36mcount_tags\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mlst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mnum_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'|'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mlst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tags'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'count'"
     ]
    }
   ],
   "source": [
    "new_df['definition'] = remove_quote(new_df['definition'])\n",
    "new_df['Channel_country'] = remove_quote(new_df['Channel_country'])\n",
    "\n",
    "count_tags(new_df)\n",
    "\n",
    "encode_country(new_df)\n",
    "new_df[pd.get_dummies(new_df['Channel_country']).columns] = pd.get_dummies(new_df['Channel_country'])[:]\n",
    "\n",
    "new_df = new_df.drop(clean_subcount(new_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "1. https://stackoverflow.com/questions/40950791/remove-quotes-from-string-in-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
